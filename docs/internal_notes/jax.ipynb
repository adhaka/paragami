{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import jax\n",
    "import jax.numpy as jnp\n",
    "import numpy as np\n",
    "from jax import grad, hessian, jit, vmap\n",
    "\n",
    "def logprob_fun(mu, x):\n",
    "    return np.sum(0.5 * (mu - x)**2)\n",
    "\n",
    "grad_fun = jit(grad(logprob_fun))\n",
    "hess_fun = jit(hessian(logprob_fun))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Paragami debugging"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import paragami\n",
    "import copy\n",
    "import unittest\n",
    "from numpy.testing import assert_array_almost_equal\n",
    "import scipy as sp\n",
    "import scipy as osp\n",
    "\n",
    "import itertools\n",
    "import json\n",
    "import collections\n",
    "\n",
    "import time\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# A pattern that matches no actual types for causing errors to test.\n",
    "class BadTestPattern(paragami.base_patterns.Pattern):\n",
    "    def __init__(self):\n",
    "        pass\n",
    "\n",
    "    def __str__(self):\n",
    "        return 'BadTestPattern'\n",
    "\n",
    "    def as_dict(self):\n",
    "        return { 'pattern': 'bad_test_pattern' }\n",
    "\n",
    "    def fold(self, flat_val, validate_value=None):\n",
    "        return 0\n",
    "\n",
    "    def flatten(self, flat_val, validate_value=None):\n",
    "        return 0\n",
    "\n",
    "    def empty(self):\n",
    "        return 0\n",
    "\n",
    "    def validate_folded(self, folded_val, validate_value=None):\n",
    "        return True, ''\n",
    "\n",
    "    def flat_indices(self, folded_bool, free):\n",
    "        return []\n",
    "\n",
    "\n",
    "def _test_pattern(testcase, pattern, valid_value,\n",
    "                  check_equal=assert_array_almost_equal,\n",
    "                  jacobian_ad_test=True):\n",
    "\n",
    "    print('Testing pattern {}'.format(pattern))\n",
    "\n",
    "    # Execute required methods.\n",
    "    empty_val = pattern.empty(valid=True)\n",
    "    pattern.flatten(empty_val, free=False)\n",
    "    empty_val = pattern.empty(valid=False)\n",
    "\n",
    "    random_val = pattern.random()\n",
    "    pattern.flatten(random_val, free=False)\n",
    "\n",
    "    str(pattern)\n",
    "\n",
    "    pattern.empty_bool(True)\n",
    "\n",
    "    # Make sure to test != using a custom test.\n",
    "    testcase.assertTrue(pattern == pattern)\n",
    "\n",
    "    ###############################\n",
    "    # Test folding and unfolding.\n",
    "    for free in [True, False, None]:\n",
    "        for free_default in [True, False, None]:\n",
    "            pattern.free_default = free_default\n",
    "            if (free_default is None) and (free is None):\n",
    "                with testcase.assertRaises(ValueError):\n",
    "                    flat_val = pattern.flatten(valid_value, free=free)\n",
    "                with testcase.assertRaises(ValueError):\n",
    "                    folded_val = pattern.fold(flat_val, free=free)\n",
    "            else:\n",
    "                flat_val = pattern.flatten(valid_value, free=free)\n",
    "                testcase.assertEqual(len(flat_val), pattern.flat_length(free))\n",
    "                folded_val = pattern.fold(flat_val, free=free)\n",
    "                check_equal(valid_value, folded_val)\n",
    "                if hasattr(valid_value, 'shape'):\n",
    "                    testcase.assertEqual(valid_value.shape, folded_val.shape)\n",
    "\n",
    "    ####################################\n",
    "    # Test conversion to and from JSON.\n",
    "    pattern_dict = pattern.as_dict()\n",
    "    json_typename = pattern.json_typename()\n",
    "    json_string = pattern.to_json()\n",
    "    json_dict = json.loads(json_string)\n",
    "    testcase.assertTrue('pattern' in json_dict.keys())\n",
    "    testcase.assertTrue(json_dict['pattern'] == json_typename)\n",
    "    new_pattern = paragami.get_pattern_from_json(json_string)\n",
    "    testcase.assertTrue(new_pattern == pattern)\n",
    "\n",
    "    # Test that you cannot covert from a different patter.\n",
    "    bad_test_pattern = BadTestPattern()\n",
    "    bad_json_string = bad_test_pattern.to_json()\n",
    "    testcase.assertFalse(pattern == bad_test_pattern)\n",
    "    testcase.assertRaises(\n",
    "        ValueError,\n",
    "        lambda: pattern.__class__.from_json(bad_json_string))\n",
    "\n",
    "    ############################################\n",
    "    # Test the freeing and unfreeing Jacobians.\n",
    "    def freeing_transform(flat_val):\n",
    "        return pattern.flatten(\n",
    "            pattern.fold(flat_val, free=False), free=True)\n",
    "\n",
    "    def unfreeing_transform(free_flat_val):\n",
    "        return pattern.flatten(\n",
    "            pattern.fold(free_flat_val, free=True), free=False)\n",
    "\n",
    "    ad_freeing_jacobian = jax.jit(jax.jacobian(freeing_transform))\n",
    "    ad_unfreeing_jacobian = jax.jit(jax.jacobian(unfreeing_transform))\n",
    "\n",
    "    for sparse in [True, False]:\n",
    "        flat_val = pattern.flatten(valid_value, free=False)\n",
    "        freeflat_val = pattern.flatten(valid_value, free=True)\n",
    "        freeing_jac = pattern.freeing_jacobian(valid_value, sparse)\n",
    "        unfreeing_jac = pattern.unfreeing_jacobian(valid_value, sparse)\n",
    "        free_len = pattern.flat_length(free=False)\n",
    "        flatfree_len = pattern.flat_length(free=True)\n",
    "\n",
    "        # Check the shapes.\n",
    "        testcase.assertTrue(freeing_jac.shape == (flatfree_len, free_len))\n",
    "        testcase.assertTrue(unfreeing_jac.shape == (free_len, flatfree_len))\n",
    "\n",
    "        # Check the values of the Jacobians.\n",
    "        if sparse:\n",
    "            # The Jacobians should be inverses of one another and full rank\n",
    "            # in the free flat space.\n",
    "            assert_array_almost_equal(\n",
    "                np.eye(flatfree_len),\n",
    "                np.array((freeing_jac @ unfreeing_jac).todense()))\n",
    "            if jacobian_ad_test:\n",
    "                assert_array_almost_equal(\n",
    "                    ad_freeing_jacobian(flat_val),\n",
    "                    np.array(freeing_jac.todense()))\n",
    "                assert_array_almost_equal(\n",
    "                    ad_unfreeing_jacobian(freeflat_val),\n",
    "                    np.array(unfreeing_jac.todense()))\n",
    "        else:\n",
    "            # The Jacobians should be inverses of one another and full rank\n",
    "            # in the free flat space.\n",
    "            assert_array_almost_equal(\n",
    "                np.eye(flatfree_len), freeing_jac @ unfreeing_jac)\n",
    "            if jacobian_ad_test:\n",
    "                assert_array_almost_equal(\n",
    "                    ad_freeing_jacobian(flat_val), freeing_jac)\n",
    "                assert_array_almost_equal(\n",
    "                    ad_unfreeing_jacobian(freeflat_val), unfreeing_jac)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<1x1 sparse matrix of type '<class 'numpy.float64'>'\n",
       "\twith 1 stored elements (1 diagonals) in DIAgonal format>"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "osp.sparse.diags(np.array([1.]))\n",
    "osp.sparse.diags([1.])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/rgiordan/Documents/git_repos/paragami/venv/lib/python3.6/site-packages/jax/lib/xla_bridge.py:130: UserWarning: No GPU/TPU found, falling back to CPU.\n",
      "  warnings.warn('No GPU/TPU found, falling back to CPU.')\n"
     ]
    }
   ],
   "source": [
    "class DummyTest(unittest.TestCase):\n",
    "    pass\n",
    "testcase = DummyTest()\n",
    "self = DummyTest()\n",
    "check_equal = assert_array_almost_equal\n",
    "\n",
    "array_pattern = paragami.NumericArrayPattern(\n",
    "    shape=(4, ), lb=-1, ub=10.0)\n",
    "pattern = paragami.PatternArray((2, 3), array_pattern)\n",
    "\n",
    "#pattern = paragami.NumericArrayPattern(shape=(500, 10, 10), lb=-1, ub=10.0)\n",
    "\n",
    "#pattern = paragami.PSDSymmetricMatrixPattern(10)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.1659209728240967\n"
     ]
    }
   ],
   "source": [
    "import cProfile\n",
    "import pstats\n",
    "valid_value = pattern.random()\n",
    "\n",
    "# Execute required methods.\n",
    "empty_val = pattern.empty(valid=True)\n",
    "flat_val = pattern.flatten(empty_val, free=False, validate_value=False)\n",
    "profile = True\n",
    "\n",
    "if profile:\n",
    "    pr = cProfile.Profile()\n",
    "    pr.enable()\n",
    "\n",
    "tic = time.time()\n",
    "for _ in range(1000):\n",
    "    pattern.flatten(empty_val, free=False, validate_value=False)\n",
    "tic = time.time() - tic; print(tic)\n",
    "\n",
    "if profile:\n",
    "    pr.disable()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "         1190152 function calls in 1.166 seconds\n",
      "\n",
      "   Ordered by: cumulative time\n",
      "\n",
      "   ncalls  tottime  percall  cumtime  percall filename:lineno(function)\n",
      "        5    0.000    0.000    1.166    0.233 interactiveshell.py:3302(run_code)\n",
      "        5    0.000    0.000    1.166    0.233 {built-in method builtins.exec}\n",
      "        1    0.005    0.005    1.166    1.166 <ipython-input-6-82a1c2739872>:15(<module>)\n",
      "     1000    0.023    0.000    1.161    0.001 pattern_containers.py:587(flatten)\n",
      "     1000    0.004    0.000    0.951    0.001 lax_numpy.py:2143(hstack)\n",
      "     7000    0.032    0.000    0.742    0.000 lax_numpy.py:2232(array)\n",
      "     1000    0.011    0.000    0.634    0.001 lax_numpy.py:2145(<listcomp>)\n",
      "     6000    0.009    0.000    0.623    0.000 lax_numpy.py:2194(atleast_1d)\n",
      "     7000    0.033    0.000    0.576    0.000 lax.py:1381(_device_put_raw)\n",
      "     1000    0.007    0.000    0.297    0.000 lax_numpy.py:2114(concatenate)\n",
      "     7000    0.012    0.000    0.220    0.000 xla.py:108(array_result_handler)\n",
      "    13000    0.013    0.000    0.204    0.000 xla.py:117(device_put)\n",
      "     1000    0.002    0.000    0.152    0.000 lax_numpy.py:2132(<listcomp>)\n",
      "     1000    0.002    0.000    0.150    0.000 lax.py:433(concatenate)\n",
      "     1000    0.002    0.000    0.148    0.000 core.py:271(bind)\n",
      "    14000    0.017    0.000    0.142    0.000 dtypes.py:253(result_type)\n",
      "     7000    0.010    0.000    0.141    0.000 util.py:91(partial)\n",
      "     1000    0.009    0.000    0.139    0.000 xla.py:222(apply_primitive)\n",
      "     1000    0.002    0.000    0.132    0.000 lax_numpy.py:260(_promote_dtypes)\n",
      "     7000    0.028    0.000    0.131    0.000 functools.py:44(update_wrapper)\n",
      "     7000    0.005    0.000    0.124    0.000 core.py:809(get_aval)\n",
      "     7000    0.015    0.000    0.118    0.000 core.py:802(concrete_aval)\n",
      "     1000    0.054    0.000    0.117    0.000 xla.py:327(_execute_compiled_primitive)\n",
      "    21000    0.023    0.000    0.109    0.000 core.py:931(__init__)\n",
      "     1000    0.001    0.000    0.101    0.000 lax_numpy.py:340(result_type)\n",
      "     7000    0.024    0.000    0.095    0.000 core.py:992(__init__)\n",
      "     7000    0.082    0.000    0.086    0.000 xla.py:124(_device_put_array)\n",
      "     7000    0.082    0.000    0.082    0.000 {method 'update' of 'dict' objects}\n",
      "    14000    0.017    0.000    0.081    0.000 core.py:1045(raise_to_shaped)\n",
      "     2000    0.004    0.000    0.072    0.000 {built-in method builtins.max}\n",
      "    21000    0.016    0.000    0.070    0.000 core.py:1064(canonicalize_shape)\n",
      "    48000    0.044    0.000    0.065    0.000 {built-in method numpy.core._multiarray_umath.implement_array_function}\n",
      "     6000    0.006    0.000    0.065    0.000 dtypes.py:236(_dtype_priority)\n",
      "    13000    0.010    0.000    0.060    0.000 xla.py:136(canonicalize_dtype)\n",
      "     1000    0.003    0.000    0.059    0.000 xla.py:329(<listcomp>)\n",
      "    18000    0.014    0.000    0.059    0.000 dtypes.py:145(issubdtype)\n",
      "    21000    0.045    0.000    0.055    0.000 util.py:29(safe_map)\n",
      "     7000    0.009    0.000    0.052    0.000 lax_numpy.py:2275(_can_call_numpy_array)\n",
      "    19000    0.013    0.000    0.047    0.000 dtypes.py:248(dtype)\n",
      "     7000    0.011    0.000    0.047    0.000 xla.py:145(_canonicalize_ndarray_dtype)\n",
      "    15000    0.009    0.000    0.046    0.000 <__array_function__ internals>:2(ndim)\n",
      "     7000    0.016    0.000    0.046    0.000 lax_numpy.py:214(_np_array)\n",
      "     6000    0.004    0.000    0.045    0.000 xla.py:1149(_device_put_device_array)\n",
      "    26000    0.016    0.000    0.043    0.000 <__array_function__ internals>:2(result_type)\n",
      "    18000    0.015    0.000    0.039    0.000 numerictypes.py:365(issubdtype)\n",
      "    14000    0.035    0.000    0.035    0.000 {built-in method numpy.array}\n",
      "     7000    0.017    0.000    0.031    0.000 lazy.py:112(array)\n",
      "     6000    0.019    0.000    0.030    0.000 xla.py:1154(_copy_device_array_to_device)\n",
      "     1000    0.003    0.000    0.029    0.000 lax_numpy.py:267(<listcomp>)\n",
      "     6000    0.006    0.000    0.026    0.000 lax.py:368(convert_element_type)\n",
      "     1000    0.006    0.000    0.025    0.000 pattern_containers.py:595(<listcomp>)\n",
      "     7000    0.008    0.000    0.024    0.000 tree_util.py:75(tree_leaves)\n",
      "    36000    0.012    0.000    0.022    0.000 numerictypes.py:293(issubclass_)\n",
      "     1000    0.012    0.000    0.020    0.000 pattern_containers.py:512(validate_folded)\n",
      "     6000    0.007    0.000    0.019    0.000 numeric_array_patterns.py:237(flatten)\n",
      "     7000    0.005    0.000    0.018    0.000 {built-in method builtins.all}\n",
      "    56010    0.017    0.000    0.017    0.000 {built-in method builtins.getattr}\n",
      "     7000    0.016    0.000    0.016    0.000 {built-in method jaxlib.pytree.flatten}\n",
      "    21000    0.016    0.000    0.016    0.000 core.py:870(__init__)\n",
      "    15000    0.007    0.000    0.015    0.000 fromnumeric.py:3037(ndim)\n",
      "     1000    0.002    0.000    0.015    0.000 xla.py:1075(__iter__)\n",
      "     7000    0.004    0.000    0.014    0.000 xla.py:1178(_force)\n",
      "    72000    0.014    0.000    0.014    0.000 {built-in method builtins.issubclass}\n",
      "     7000    0.003    0.000    0.014    0.000 _asarray.py:16(asarray)\n",
      "     7000    0.005    0.000    0.014    0.000 <__array_function__ internals>:2(shape)\n",
      "    12000    0.006    0.000    0.014    0.000 numeric_array_patterns.py:197(validate_folded)\n",
      "     1000    0.009    0.000    0.013    0.000 xla.py:993(_value)\n",
      "    19000    0.009    0.000    0.013    0.000 lax_numpy.py:2276(<genexpr>)\n",
      "     7000    0.010    0.000    0.011    0.000 lazy.py:143(is_trivial)\n",
      "    13000    0.010    0.000    0.010    0.000 xla_bridge.py:173(get_device_backend)\n",
      "    79000    0.009    0.000    0.009    0.000 {built-in method builtins.len}\n",
      "    17000    0.008    0.000    0.009    0.000 xla.py:1016(ndim)\n",
      "    46002    0.009    0.000    0.009    0.000 {built-in method builtins.isinstance}\n",
      "    14000    0.009    0.000    0.009    0.000 xla.py:979(__init__)\n",
      "     7000    0.008    0.000    0.008    0.000 lax.py:5892(_check_user_dtype_supported)\n",
      "    12000    0.006    0.000    0.008    0.000 numeric_array_patterns.py:188(_validate_folded_shape)\n",
      "     7000    0.005    0.000    0.008    0.000 lazy.py:38(__new__)\n",
      "    24000    0.007    0.000    0.007    0.000 core.py:1058(_canonicalize_dimension)\n",
      "    28000    0.007    0.000    0.007    0.000 {built-in method builtins.setattr}\n",
      "    18000    0.004    0.000    0.007    0.000 dtypes.py:134(_issubclass)\n",
      "     7000    0.006    0.000    0.006    0.000 {method 'mro' of 'type' objects}\n",
      "     6000    0.002    0.000    0.006    0.000 xla.py:215(arg_spec)\n",
      "     1000    0.002    0.000    0.006    0.000 core.py:722(find_top_trace)\n",
      "     1000    0.002    0.000    0.006    0.000 {built-in method _functools.reduce}\n",
      "     6000    0.006    0.000    0.006    0.000 {method 'flatten' of 'numpy.ndarray' objects}\n",
      "     7000    0.004    0.000    0.005    0.000 <string>:12(__new__)\n",
      "    14000    0.004    0.000    0.004    0.000 {built-in method __new__ of type object at 0x9d12c0}\n",
      "     5000    0.004    0.000    0.004    0.000 dtypes.py:209(promote_types)\n",
      "    26000    0.004    0.000    0.004    0.000 {method 'get' of 'dict' objects}\n",
      "     6000    0.003    0.000    0.004    0.000 xla.py:158(abstractify)\n",
      "     6000    0.003    0.000    0.004    0.000 core.py:948(__hash__)\n",
      "     7000    0.003    0.000    0.003    0.000 fromnumeric.py:1903(shape)\n",
      "    26000    0.003    0.000    0.003    0.000 multiarray.py:635(result_type)\n",
      "     6000    0.003    0.000    0.003    0.000 core.py:943(__eq__)\n",
      "     1000    0.003    0.000    0.003    0.000 {method 'astype' of 'numpy.ndarray' objects}\n",
      "     1000    0.001    0.000    0.003    0.000 config.py:134(__getattr__)\n",
      "     7000    0.003    0.000    0.003    0.000 xla.py:1133(is_device_constant)\n",
      "    12000    0.003    0.000    0.003    0.000 xla.py:1008(dtype)\n",
      "     1000    0.002    0.000    0.003    0.000 core.py:723(<genexpr>)\n",
      "    15000    0.002    0.000    0.002    0.000 fromnumeric.py:3033(_ndim_dispatcher)\n",
      "    12000    0.002    0.000    0.002    0.000 numeric_array_patterns.py:249(shape)\n",
      "     1000    0.001    0.000    0.002    0.000 config.py:59(read)\n",
      "     6000    0.002    0.000    0.002    0.000 dtypes.py:230(is_python_scalar)\n",
      "     7000    0.001    0.000    0.001    0.000 fromnumeric.py:1899(_shape_dispatcher)\n",
      "     1000    0.001    0.000    0.001    0.000 lax.py:5908(_canonicalize_axis)\n",
      "     7000    0.001    0.000    0.001    0.000 base_patterns.py:159(_free_with_default)\n",
      "     6000    0.001    0.000    0.001    0.000 {built-in method builtins.hash}\n",
      "     6000    0.001    0.000    0.001    0.000 {method 'append' of 'list' objects}\n",
      "     6000    0.001    0.000    0.001    0.000 xla.py:72(identity)\n",
      "     1000    0.001    0.000    0.001    0.000 config.py:72(check_exists)\n",
      "     1000    0.000    0.000    0.000    0.000 xla.py:947(_check_if_deleted)\n",
      "     1000    0.000    0.000    0.000    0.000 dtypes.py:263(<listcomp>)\n",
      "     1000    0.000    0.000    0.000    0.000 {built-in method _operator.index}\n",
      "        5    0.000    0.000    0.000    0.000 codeop.py:132(__call__)\n",
      "        5    0.000    0.000    0.000    0.000 {built-in method builtins.compile}\n",
      "        1    0.000    0.000    0.000    0.000 <ipython-input-6-82a1c2739872>:17(<module>)\n",
      "        1    0.000    0.000    0.000    0.000 {built-in method builtins.print}\n",
      "        2    0.000    0.000    0.000    0.000 iostream.py:386(write)\n",
      "        3    0.000    0.000    0.000    0.000 iostream.py:197(schedule)\n",
      "        3    0.000    0.000    0.000    0.000 socket.py:357(send)\n",
      "        5    0.000    0.000    0.000    0.000 contextlib.py:157(helper)\n",
      "       10    0.000    0.000    0.000    0.000 {built-in method builtins.next}\n",
      "        2    0.000    0.000    0.000    0.000 iostream.py:323(_schedule_flush)\n",
      "        3    0.000    0.000    0.000    0.000 threading.py:1104(is_alive)\n",
      "        5    0.000    0.000    0.000    0.000 contextlib.py:59(__init__)\n",
      "        5    0.000    0.000    0.000    0.000 contextlib.py:85(__exit__)\n",
      "        5    0.000    0.000    0.000    0.000 contextlib.py:79(__enter__)\n",
      "        5    0.000    0.000    0.000    0.000 hooks.py:103(__call__)\n",
      "        5    0.000    0.000    0.000    0.000 traitlets.py:545(__get__)\n",
      "       10    0.000    0.000    0.000    0.000 compilerop.py:138(extra_flags)\n",
      "        5    0.000    0.000    0.000    0.000 interactiveshell.py:117(<lambda>)\n",
      "        3    0.000    0.000    0.000    0.000 threading.py:1062(_wait_for_tstate_lock)\n",
      "        2    0.000    0.000    0.000    0.000 iostream.py:310(_is_master_process)\n",
      "        5    0.000    0.000    0.000    0.000 ipstruct.py:125(__getattr__)\n",
      "        2    0.000    0.000    0.000    0.000 {built-in method posix.getpid}\n",
      "        1    0.000    0.000    0.000    0.000 <ipython-input-6-82a1c2739872>:14(<module>)\n",
      "        1    0.000    0.000    0.000    0.000 <ipython-input-6-82a1c2739872>:19(<module>)\n",
      "        5    0.000    0.000    0.000    0.000 traitlets.py:526(get)\n",
      "        3    0.000    0.000    0.000    0.000 {method 'acquire' of '_thread.lock' objects}\n",
      "        5    0.000    0.000    0.000    0.000 interactiveshell.py:3244(compare)\n",
      "        5    0.000    0.000    0.000    0.000 interactiveshell.py:1276(user_global_ns)\n",
      "        3    0.000    0.000    0.000    0.000 threading.py:506(is_set)\n",
      "        2    0.000    0.000    0.000    0.000 {built-in method time.time}\n",
      "        3    0.000    0.000    0.000    0.000 iostream.py:93(_event_pipe)\n",
      "        5    0.000    0.000    0.000    0.000 hooks.py:168(pre_run_code_hook)\n",
      "        3    0.000    0.000    0.000    0.000 {method 'append' of 'collections.deque' objects}\n",
      "        1    0.000    0.000    0.000    0.000 {method 'disable' of '_lsprof.Profiler' objects}\n",
      "\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<pstats.Stats at 0x7f516b4faef0>"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ps = pstats.Stats(pr).strip_dirs().sort_stats('cumulative')\n",
    "ps.print_stats()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "empty_val = pattern.empty(valid=False)\n",
    "\n",
    "\n",
    "random_val = pattern.random()\n",
    "pattern.flatten(random_val, free=False)\n",
    "\n",
    "str(pattern)\n",
    "\n",
    "pattern.empty_bool(True)\n",
    "\n",
    "# Make sure to test != using a custom test.\n",
    "testcase.assertTrue(pattern == pattern)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "###############################\n",
    "# Test folding and unfolding.\n",
    "for free in [True, False, None]:\n",
    "    for free_default in [True, False, None]:\n",
    "        pattern.free_default = free_default\n",
    "        if (free_default is None) and (free is None):\n",
    "            with testcase.assertRaises(ValueError):\n",
    "                flat_val = pattern.flatten(valid_value, free=free)\n",
    "            with testcase.assertRaises(ValueError):\n",
    "                folded_val = pattern.fold(flat_val, free=free)\n",
    "        else:\n",
    "            flat_val = pattern.flatten(valid_value, free=free)\n",
    "            testcase.assertEqual(len(flat_val), pattern.flat_length(free))\n",
    "            folded_val = pattern.fold(flat_val, free=free)\n",
    "            check_equal(valid_value, folded_val)\n",
    "            if hasattr(valid_value, 'shape'):\n",
    "                testcase.assertEqual(valid_value.shape, folded_val.shape)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "ename": "AssertionError",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAssertionError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-9-a871fdc9ebee>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0;32massert\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mAssertionError\u001b[0m: "
     ]
    }
   ],
   "source": [
    "assert False"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Generic Jax stuff"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = onp.random.random(100)\n",
    "mu = onp.random.random(100)\n",
    "\n",
    "# I would have expected this to get rid of the annoying warning but it does not.\n",
    "cpu_device = jax.devices('cpu')[0]\n",
    "jax.device_put(x, cpu_device);\n",
    "jax.device_put(mu, cpu_device);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "g = grad_fun(mu, x)\n",
    "h = hess_fun(mu, x)\n",
    "print(np.max(np.abs(g - (mu - x))))\n",
    "print(np.max(np.abs(h - np.eye(100))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# https://jax.readthedocs.io/en/latest/notebooks/Custom_derivative_rules_for_Python_code.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from jax import custom_jvp\n",
    "import jax.numpy as jnp\n",
    "\n",
    "# f :: a -> b\n",
    "@custom_jvp\n",
    "def f(x):\n",
    "    return jnp.sin(x)\n",
    "\n",
    "# f_jvp :: (a, T a) -> (b, T b)\n",
    "def f_jvp(primals, tangents):\n",
    "    x, = primals\n",
    "    t, = tangents\n",
    "    return f(x), jnp.cos(x) * t\n",
    "\n",
    "f.defjvp(f_jvp)\n",
    "\n",
    "print(type(f(0.5)))\n",
    "\n",
    "print('Use jax')\n",
    "foo = jax.numpy.asarray(f(0.5) + 3)\n",
    "print(foo, type(foo))\n",
    "print(isinstance(foo, onp.ndarray))\n",
    "print(isinstance(foo, jax.numpy.ndarray))\n",
    "\n",
    "print('Use numpy')\n",
    "foo = onp.asarray(f(0.5) + 3)\n",
    "print(isinstance(foo, onp.ndarray))\n",
    "print(isinstance(foo, jax.numpy.ndarray))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "@custom_jvp\n",
    "def f(x, y):\n",
    "    return jnp.sin(x) * y\n",
    "\n",
    "f.defjvps(lambda x_dot, primal_out, x, y: jnp.cos(x) * x_dot * y,\n",
    "          lambda y_dot, primal_out, x, y: jnp.sin(x) * y_dot)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "foo = np.array([1, 2, 3])\n",
    "print(jax.ops.index_update(foo, [1, 2], [10, 20]))\n",
    "\n",
    "foo = np.array([[1, 2], [3, 4]])\n",
    "print(jax.ops.index_update(foo, [1, 2], [10, 20]))\n",
    "\n",
    "inds = np.triu_indices(2)\n",
    "print(inds)\n",
    "print(jax.ops.index_update(foo, inds, [10, 20, 30]))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#jax.sp.logsumexp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vec = np.arange(0, 3, dtype=np.float32) + 1\n",
    "np.diag(vec)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def _exp_matrix_diagonal(mat):\n",
    "    assert mat.shape[0] == mat.shape[1]\n",
    "    dim = mat.shape[0]\n",
    "    diag_inds = (np.arange(dim), np.arange(dim))\n",
    "    exp_diags = np.exp(np.diag(mat))\n",
    "    return(jax.ops.index_update(mat, diag_inds, exp_diags))\n",
    "\n",
    "def _log_matrix_diagonal(mat):\n",
    "    assert mat.shape[0] == mat.shape[1]\n",
    "    dim = mat.shape[0]\n",
    "    diag_inds = (np.arange(dim), np.arange(dim))\n",
    "    log_diags = np.log(np.diag(mat))\n",
    "    return(jax.ops.index_update(mat, diag_inds, log_diags))\n",
    "\n",
    "mat = onp.random.random((3, 3))\n",
    "print(mat)\n",
    "print(_exp_matrix_diagonal(mat))\n",
    "print(jax.jacobian(_exp_matrix_diagonal)(mat))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "np.triu_indices(5)\n",
    "\n",
    "def pack_vec(vec, dim):\n",
    "    assert len(vec) == dim * (dim + 1) / 2\n",
    "    mat = np.zeros((dim, dim))\n",
    "    inds = np.tril_indices(dim)\n",
    "    return(jax.ops.index_update(mat, inds, vec))\n",
    "\n",
    "vec = np.arange(0, 6, dtype=np.float32) + 1\n",
    "print(vec.dtype)\n",
    "print(pack_vec(vec, 3))\n",
    "\n",
    "print('Raw:')\n",
    "print(jax.jacobian(pack_vec)(vec, 3))\n",
    "\n",
    "print('JIT:')\n",
    "jac_fun = jit(jax.jacobian(pack_vec), static_argnums=1)\n",
    "print(jac_fun(vec, 3))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Fails\n",
    "\n",
    "# @custom_jvp\n",
    "# def replace_ind(x, v, i):\n",
    "#     x[i] = v\n",
    "#     return x\n",
    "\n",
    "# replace_ind.defjvps(\n",
    "#     lambda x_dot, ans, x, v, i: replace_ind(x_dot, 0.0, i),\n",
    "#     lambda v_dot, ans, x, v, i: replace_ind(ans, v_dot, i),\n",
    "#     None)\n",
    "\n",
    "# x = np.array([1.0, 2.0, 3.5])\n",
    "# replace_ind(x, 10.0, 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Why is jax slow?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import timeit\n",
    "foo = np.random.random((100, 10, 7)) + 1\n",
    "number = 1000\n",
    "\n",
    "\n",
    "def _unconstrain_array(array, lb, ub, np):\n",
    "    # Assume that the inputs obey the constraints, lb < ub and\n",
    "    # lb <= array <= ub, which are checked in the pattern.\n",
    "    if ub == float(\"inf\"):\n",
    "        if lb == -float(\"inf\"):\n",
    "            # For consistent behavior, never return a reference.\n",
    "            # Note that deepcopy will cause jax to fail.\n",
    "            return copy.copy(array)\n",
    "        else:\n",
    "            return np.log(array - lb)\n",
    "    else:  # the upper bound is finite\n",
    "        if lb == -float(\"inf\"):\n",
    "            return -1 * np.log(ub - array)\n",
    "        else:\n",
    "            return np.log(array - lb) - np.log(ub - array)\n",
    "\n",
    "setup_str = \"from __main__ import jnp, np, foo, _unconstrain_array\"\n",
    "print(timeit.timeit('_unconstrain_array(foo, lb=0.5, ub=10.0, np=jnp)', setup=setup_str, number=number))\n",
    "print(timeit.timeit('_unconstrain_array(foo, lb=0.5, ub=10.0, np=np)', setup=setup_str, number=number))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import timeit\n",
    "foo = np.random.random((100, 10, 7)) + 1\n",
    "number = 5000\n",
    "\n",
    "setup_str = \"from __main__ import jnp, np, foo\"\n",
    "print(timeit.timeit('jnp.atleast_1d(foo)', setup=setup_str, number=number))\n",
    "print(timeit.timeit('np.atleast_1d(foo)', setup=setup_str, number=number))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.6976880369984428\n",
      "0.033834197998658055\n"
     ]
    }
   ],
   "source": [
    "import timeit\n",
    "foo = np.random.random((100, 10, 7)) + 1\n",
    "number = 5000\n",
    "\n",
    "setup_str = \"from __main__ import jnp, np, foo\"\n",
    "print(timeit.timeit('jnp.all(foo < 0.)', setup=setup_str, number=number))\n",
    "print(timeit.timeit('np.all(foo < 0.)', setup=setup_str, number=number))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.45507077799993567\n",
      "0.18438938400140614\n",
      "0.004715634000604041\n"
     ]
    }
   ],
   "source": [
    "import jax\n",
    "import jax.numpy as jnp\n",
    "import numpy as np\n",
    "\n",
    "import timeit\n",
    "foo = [ np.random.random((100, )) for _ in range(10) ]\n",
    "number = 500\n",
    "\n",
    "@jax.jit\n",
    "def jitted_fun(x):\n",
    "    return jnp.hstack(x)\n",
    "\n",
    "setup_str = \"from __main__ import jnp, np, foo, jitted_fun\"\n",
    "print(timeit.timeit('y = jnp.hstack(foo)', setup=setup_str, number=number))\n",
    "print(timeit.timeit('y = jitted_fun(foo)', setup=setup_str, number=number))\n",
    "print(timeit.timeit('y = np.hstack(foo)', setup=setup_str, number=number))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "paragami_sandbox",
   "language": "python",
   "name": "paragami_sandbox"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
