{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import paragami\n",
    "import autograd\n",
    "import autograd.numpy as np\n",
    "\n",
    "import time\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Hessian time:  0.986060380935669\n"
     ]
    }
   ],
   "source": [
    "np.random.seed(42)\n",
    "\n",
    "group_size = 3\n",
    "num_groups = 10\n",
    "d = group_size * num_groups\n",
    "\n",
    "def get_pd_mat(d): \n",
    "    a = np.random.random((d, d))\n",
    "    a = a + a.T + np.eye(d)\n",
    "    return a\n",
    "\n",
    "group_mats = np.array([ get_pd_mat(group_size) for g in range(num_groups) ])\n",
    "pattern = paragami.PatternDict()\n",
    "pattern['array'] = paragami.NumericArrayPattern((num_groups, group_size))\n",
    "mat_pattern = paragami.PSDSymmetricMatrixPattern(size=group_size)\n",
    "pattern['mats'] = paragami.PatternArray((num_groups,), mat_pattern) \n",
    "\n",
    "def f(x_dict, w):\n",
    "    return 0.5 * np.einsum('n,nij,ni,nj',\n",
    "                           w, x_dict['mats'], x_dict['array'], x_dict['array'])\n",
    "\n",
    "w = np.ones(num_groups)\n",
    "x_dict = pattern.random()\n",
    "f(x_dict, w)\n",
    "\n",
    "f_flat = paragami.FlattenFunctionInput(\n",
    "    f, argnums=0, free=True, patterns=pattern)\n",
    "\n",
    "x_flat = pattern.flatten(x_dict, free=True)\n",
    "f_flat(x_flat, w)\n",
    "\n",
    "f_grad = autograd.grad(f_flat, argnum=0)\n",
    "f_hess = autograd.hessian(f_flat, argnum=0)\n",
    "\n",
    "hess_time = time.time()\n",
    "h0 = f_hess(x_flat, w)\n",
    "hess_time = time.time() - hess_time\n",
    "print('Hessian time: ', hess_time)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 0,  1,  2, 30, 31, 32, 33, 34, 35])"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "g = 0\n",
    "x_bool = pattern.empty_bool(False)\n",
    "x_bool['array'][g, :] = True\n",
    "x_bool['mats'][g, :, :] = True\n",
    "pattern.flat_indices(x_bool, free=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Missing indices:  []\n",
      "Length difference:  0\n"
     ]
    }
   ],
   "source": [
    "inds = []\n",
    "for g in range(num_groups):\n",
    "    x_bool = pattern.empty_bool(False)\n",
    "    x_bool['array'][g, :] = True\n",
    "    x_bool['mats'][g, :, :] = True\n",
    "    inds.append(pattern.flat_indices(x_bool, free=True))\n",
    "inds = np.array(inds)\n",
    "print('Missing indices: ', np.setdiff1d(np.arange(len(x_flat)), inds.flatten()))\n",
    "print('Length difference: ', len(x_flat) - len(inds.flatten()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4.183904711016181e-15"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sparse_hess = paragami.SparseBlockHessian(f_flat, inds)\n",
    "block_hess = sparse_hess.get_block_hessian(x_flat, w)\n",
    "\n",
    "np.linalg.norm(block_hess - h0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A reverse diff version?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This works!\n",
    "\n",
    "from autograd.test_util import check_grads\n",
    "\n",
    "d = 10\n",
    "perm = np.random.choice(d, d, replace=False)\n",
    "\n",
    "x = np.random.random(d)\n",
    "a = get_pd_mat(d)\n",
    "def foo(x):\n",
    "    x_perm = x[perm]\n",
    "    return np.dot(x_perm, a @ x_perm)\n",
    "\n",
    "check_grads(foo)(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# https://stackoverflow.com/questions/11649577/how-to-invert-a-permutation-array-in-numpy\n",
    "def invert_permutation(p):\n",
    "    s = np.empty(p.size, p.dtype)\n",
    "    s[p] = np.arange(p.size)\n",
    "    return s\n",
    "\n",
    "num_blocks = inds.shape[0]\n",
    "block_size = inds.shape[1]\n",
    "perm = inds.flatten()\n",
    "inv_perm = invert_permutation(perm)\n",
    "\n",
    "def perm_fun(x_block, w_group):\n",
    "    # This won't work, because each block must be a different value.\n",
    "    assert len(x_block) == block_size\n",
    "    x = np.repeat(x_block, num_blocks)\n",
    "    x_flat = x[inv_perm] \n",
    "    return f_flat(x_flat, w_group)\n",
    "    \n",
    "x_block = np.random.random(block_size)\n",
    "fun_wrapper(x_block, w)\n",
    "\n",
    "check_grads(perm_fun)(x_block, w)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Should be zero:  0.0\n"
     ]
    }
   ],
   "source": [
    "from paragami.sensitivity_lib import _append_jvp\n",
    "opt_par = x_flat\n",
    "weights = w\n",
    "\n",
    "f_flat = paragami.FlattenFunctionInput(\n",
    "    lambda x: f(x, w), argnums=0, free=True, patterns=pattern)\n",
    "\n",
    "f_grad = autograd.grad(f_flat, argnum=0)\n",
    "f_fwd_hess = _append_jvp(f_grad, num_base_args=1)\n",
    "\n",
    "i = 2\n",
    "v = np.zeros(len(opt_par))\n",
    "v[i] = 1\n",
    "print('Should be zero: ', np.linalg.norm(f_fwd_hess(opt_par, v) - h0[i, :]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "[0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "[ 0.00000000e+00  0.00000000e+00  0.00000000e+00 -2.22044605e-16\n",
      "  0.00000000e+00  0.00000000e+00  0.00000000e+00  0.00000000e+00\n",
      "  0.00000000e+00]\n",
      "[0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "[0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "[0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "[0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "[ 0.0000000e+00  0.0000000e+00  0.0000000e+00 -4.4408921e-16\n",
      "  0.0000000e+00  0.0000000e+00  0.0000000e+00  0.0000000e+00\n",
      "  0.0000000e+00]\n",
      "[0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "[0. 0. 0. 0. 0. 0. 0. 0. 0.]\n"
     ]
    }
   ],
   "source": [
    "def hess_summed_term(opt_par, ib):\n",
    "    \"\"\"ib = block index\n",
    "    \"\"\"\n",
    "    v = np.zeros_like(opt_par)\n",
    "    v[inds[:, ib]] = 1\n",
    "    return f_fwd_hess(opt_par, v)\n",
    "\n",
    "g1 = 0\n",
    "hess_prod = hess_summed_term(opt_par, g1)\n",
    "for g2 in range(num_groups):\n",
    "    hess_inds = inds[g2, :]\n",
    "    print(hess_prod[hess_inds] - h0[hess_inds, hess_inds[g1]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "7\n",
      "8\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "4.327093765572431e-15"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from scipy.sparse import coo_matrix\n",
    "\n",
    "mat_vals = [] # These will be the entries of the Hessian\n",
    "mat_rows = [] # These will be the row indices\n",
    "mat_cols = [] # These will be the column indices\n",
    "\n",
    "component_count = 0\n",
    "for ib in range(block_size):\n",
    "    hess_prod = hess_summed_term(opt_par, ib)\n",
    "    for b in range(num_blocks):\n",
    "        hess_inds = inds[b, :]\n",
    "        mat_vals.extend(hess_prod[hess_inds])\n",
    "        mat_rows.extend(hess_inds)\n",
    "        mat_cols.extend(np.full(block_size, hess_inds[ib]))\n",
    "\n",
    "d = len(opt_par)\n",
    "h_sparse = coo_matrix((mat_vals, (mat_rows, mat_cols)), (d, d))\n",
    "\n",
    "np.linalg.norm(h_sparse - h0)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
