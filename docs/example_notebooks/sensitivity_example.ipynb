{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import paragami\n",
    "\n",
    "import autograd\n",
    "from autograd import numpy as np\n",
    "import copy\n",
    "\n",
    "# Use the original scipy for functions we don't need to differentiate.\n",
    "import scipy as osp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.seed(42)\n",
    "\n",
    "num_obs = 500\n",
    "data_dim = 3\n",
    "\n",
    "# True values of parameters\n",
    "true_sigma = \\\n",
    "    np.eye(3) * np.diag(np.arange(0, data_dim)) + \\\n",
    "    np.random.random((data_dim, data_dim)) * 0.1\n",
    "true_sigma = 0.5 * (true_sigma + true_sigma.T)\n",
    "true_mu = np.arange(0, data_dim)\n",
    "\n",
    "true_norm_param_dict = dict()\n",
    "true_norm_param_dict['mu'] = true_mu\n",
    "true_norm_param_dict['sigma'] = true_sigma\n",
    "\n",
    "# Data\n",
    "data = np.random.multivariate_normal(\n",
    "    mean=true_norm_param_dict['mu'],\n",
    "    cov=true_norm_param_dict['sigma'],\n",
    "    size=(num_obs, ))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss at true parameter: 66.51345919899458\n"
     ]
    }
   ],
   "source": [
    "def get_mvn_log_probs(obs, mean, cov):\n",
    "    cov_inv = np.linalg.inv(cov)\n",
    "    cov_det_sign, cov_log_det = np.linalg.slogdet(cov)\n",
    "    if cov_det_sign <= 0:\n",
    "        return np.full(float('inf'), obs.shape[0])\n",
    "    else:\n",
    "        obs_centered = obs - np.expand_dims(mean, axis=0)\n",
    "        return -0.5 * (\n",
    "            np.einsum('ni,ij,nj->n', obs_centered, cov_inv, obs_centered) + \\\n",
    "            cov_log_det)\n",
    "\n",
    "def get_data_lp(data, norm_param_dict, weights):\n",
    "    data_lp = np.sum(weights *\n",
    "                     get_mvn_log_probs(\n",
    "                         data,\n",
    "                         mean=norm_param_dict['mu'],\n",
    "                         cov=norm_param_dict['sigma']))\n",
    "    return data_lp\n",
    "\n",
    "def get_prior_lp(norm_param_dict, prior_param_dict):\n",
    "    data_dim = len(prior_param_dict['prior_mean']) \n",
    "    prior_cov = np.eye(data_dim) * prior_param_dict['prior_sd']\n",
    "    prior_lp = get_mvn_log_probs(\n",
    "        obs=np.expand_dims(norm_param_dict['mu'], axis=0),\n",
    "        mean=prior_param_dict['prior_mean'],\n",
    "        cov=prior_cov)\n",
    "\n",
    "    # Sum so as to return a scalar.\n",
    "    return np.sum(prior_lp)\n",
    "\n",
    "def get_loss(data, norm_param_dict, prior_param_dict, weights):\n",
    "    return -1 * (get_prior_lp(norm_param_dict, prior_param_dict) +\n",
    "                 get_data_lp(data, norm_param_dict, weights))\n",
    "    \n",
    "class NormalModel():\n",
    "    def __init__(self, data):\n",
    "        self.data = data\n",
    "        self.num_obs = self.data.shape[0]\n",
    "        self.data_dim = self.data.shape[1]\n",
    "                \n",
    "        # Reasonable defaults for the priors and weights.\n",
    "        self.set_prior(np.full(self.data_dim, 0.), 10)\n",
    "        self.set_weights(np.full(self.num_obs, 1.0))\n",
    "                \n",
    "    def set_weights(self, weights):\n",
    "        self.weights = weights\n",
    "    \n",
    "    def set_prior(self, prior_mean, prior_sd):\n",
    "        self.prior_dict = dict()\n",
    "        self.prior_dict['prior_mean'] = prior_mean\n",
    "        self.prior_dict['prior_sd'] = prior_sd\n",
    "\n",
    "    def get_loss_for_opt(self, norm_param_dict):\n",
    "        return get_loss(\n",
    "            self.data, norm_param_dict, self.prior_dict, self.weights)\n",
    "    \n",
    "    def get_loss_by_prior(self, norm_param_dict, prior_dict):\n",
    "        return get_loss(\n",
    "            self.data, norm_param_dict, prior_dict, self.weights)\n",
    "\n",
    "    def get_loss_by_weights(self, norm_param_dict, weights):\n",
    "        return get_loss(\n",
    "            self.data, norm_param_dict, self.prior_dict, weights)\n",
    "\n",
    "    \n",
    "model = NormalModel(data)\n",
    "orig_prior_dict = copy.deepcopy(model.prior_dict)\n",
    "print('Loss at true parameter: {}'.format(model.get_loss_for_opt(true_norm_param_dict)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Define patterns."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "norm_pattern = paragami.PatternDict()\n",
    "norm_pattern['mu'] = paragami.NumericArrayPattern(shape=(data_dim, ))\n",
    "norm_pattern['sigma'] = paragami.PSDMatrixPattern(size=data_dim)\n",
    "\n",
    "prior_pattern = paragami.PatternDict()\n",
    "prior_pattern['prior_mean'] = paragami.NumericArrayPattern(shape=(data_dim, ))\n",
    "prior_pattern['prior_sd'] = paragami.NumericArrayPattern(shape=(1, ), lb=0.0)\n",
    "\n",
    "weight_pattern = paragami.NumericArrayPattern(shape=(num_obs, ))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Warning: A bad approximation caused failure to predict improvement.\n",
      "         Current function value: 61.949845\n",
      "         Iterations: 18\n",
      "         Function evaluations: 20\n",
      "         Gradient evaluations: 17\n",
      "         Hessian evaluations: 17\n"
     ]
    }
   ],
   "source": [
    "# Optimize.\n",
    "opt_fun = paragami.FlattenedFunction(\n",
    "    original_fun=model.get_loss_for_opt,\n",
    "    patterns=norm_pattern,\n",
    "    free=True)\n",
    "opt_fun_grad = autograd.grad(opt_fun)\n",
    "opt_fun_hessian = autograd.hessian(opt_fun)\n",
    "\n",
    "def get_optimum(init_param):\n",
    "    return osp.optimize.minimize(\n",
    "        method='trust-ncg',\n",
    "        x0=init_param,\n",
    "        fun=opt_fun,\n",
    "        jac=opt_fun_grad,\n",
    "        hess=opt_fun_hessian,\n",
    "        options={'gtol': 1e-8, 'disp': True})\n",
    "\n",
    "# Initialize with zeros.\n",
    "init_param = np.zeros(norm_pattern.flat_length(free=True))\n",
    "mle_opt = get_optimum(init_param)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "OrderedDict([('mu', array([0.00834318, 0.95331727, 1.89785702])), ('sigma', array([[0.03865699, 0.08549517, 0.03813799],\n",
      "       [0.08549517, 1.05532374, 0.09781211],\n",
      "       [0.03813799, 0.09781211, 1.91488878]]))])\n",
      "{'sigma': array([[0.03745401, 0.07746864, 0.03950388],\n",
      "       [0.07746864, 1.01560186, 0.05110853],\n",
      "       [0.03950388, 0.05110853, 2.0601115 ]]), 'mu': array([0, 1, 2])}\n"
     ]
    }
   ],
   "source": [
    "opt_norm_param_dict = norm_pattern.fold(mle_opt.x, free=True)\n",
    "print(opt_norm_param_dict)\n",
    "print(true_norm_param_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'int' object has no attribute 'flatten'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-28-3a7a184c98fa>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      8\u001b[0m         \u001b[0mvalidate_optimum\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m         \u001b[0mopt_par_is_free\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 10\u001b[0;31m         hyper_par_is_free=False)\n\u001b[0m",
      "\u001b[0;32m~/Documents/git_repos/paragami/paragami/optimization_lib.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, objective_fun, opt_par_pattern, hyper_par_pattern, opt_par_folded_value, hyper_par_folded_value, opt_par_is_free, hyper_par_is_free, validate_optimum, hessian_at_opt, factorize_hessian, hyper_par_objective_fun)\u001b[0m\n\u001b[1;32m     54\u001b[0m         self.set_base_values(\n\u001b[1;32m     55\u001b[0m             \u001b[0mopt_par_folded_value\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhyper_par_folded_value\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 56\u001b[0;31m             hessian_at_opt, factorize_hessian, validate=validate_optimum)\n\u001b[0m\u001b[1;32m     57\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     58\u001b[0m     def set_base_values(self,\n",
      "\u001b[0;32m~/Documents/git_repos/paragami/paragami/optimization_lib.py\u001b[0m in \u001b[0;36mset_base_values\u001b[0;34m(self, opt_par_folded_value, hyper_par_folded_value, hessian_at_opt, factorize_hessian, validate, grad_tol)\u001b[0m\n\u001b[1;32m     65\u001b[0m             opt_par_folded_value, free=self._opt_par_is_free)\n\u001b[1;32m     66\u001b[0m         self._hyper0 = self._hyper_par_pattern.flatten(\n\u001b[0;32m---> 67\u001b[0;31m             hyper_par_folded_value, free=self._hyper_par_is_free)\n\u001b[0m\u001b[1;32m     68\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     69\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mvalidate\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Documents/git_repos/paragami/paragami/pattern_containers.py\u001b[0m in \u001b[0;36mflatten\u001b[0;34m(self, folded_val, free, validate)\u001b[0m\n\u001b[1;32m    148\u001b[0m             \u001b[0mflat_val\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0moffset\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moffset\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mpattern_flat_length\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m\\\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    149\u001b[0m                 pattern.flatten(\n\u001b[0;32m--> 150\u001b[0;31m                     folded_val[pattern_name], free=free, validate=validate)\n\u001b[0m\u001b[1;32m    151\u001b[0m             \u001b[0moffset\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0mpattern_flat_length\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    152\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mflat_val\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Documents/git_repos/paragami/paragami/numeric_array_patterns.py\u001b[0m in \u001b[0;36mflatten\u001b[0;34m(self, folded_val, free, validate)\u001b[0m\n\u001b[1;32m    180\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_free_flatten\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfolded_val\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalidate\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    181\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 182\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_notfree_flatten\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfolded_val\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalidate\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    183\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    184\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mshape\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Documents/git_repos/paragami/paragami/numeric_array_patterns.py\u001b[0m in \u001b[0;36m_notfree_flatten\u001b[0;34m(self, folded_val, validate)\u001b[0m\n\u001b[1;32m    165\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_notfree_flatten\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfolded_val\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalidate\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    166\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcheck_folded\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfolded_val\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalidate\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 167\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mfolded_val\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mflatten\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    168\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    169\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mfold\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mflat_val\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfree\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalidate\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'int' object has no attribute 'flatten'"
     ]
    }
   ],
   "source": [
    "prior_sens = \\\n",
    "    paragami.HyperparameterSensitivityLinearApproximation(\n",
    "        objective_fun=model.get_loss_by_prior,\n",
    "        opt_par_pattern=norm_pattern,\n",
    "        hyper_par_pattern=prior_pattern,\n",
    "        opt_par_folded_value=opt_norm_param_dict,\n",
    "        hyper_par_folded_value=model.prior_dict,\n",
    "        validate_optimum=False,\n",
    "        opt_par_is_free=True,\n",
    "        hyper_par_is_free=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# This helper function lets us easily see the differences in parameters.\n",
    "def get_norm_param_diff(par1, par2):\n",
    "    diff = \\\n",
    "        norm_pattern.flatten(par1, free=False, validate=False) - \\\n",
    "        norm_pattern.flatten(par2, free=False, validate=False)\n",
    "    return norm_pattern.fold(diff, free=False, validate=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Warning: A bad approximation caused failure to predict improvement.\n",
      "         Current function value: 212.694887\n",
      "         Iterations: 12\n",
      "         Function evaluations: 14\n",
      "         Gradient evaluations: 13\n",
      "         Hessian evaluations: 13\n"
     ]
    }
   ],
   "source": [
    "# Change the prior.\n",
    "new_prior_dict = copy.deepcopy(orig_prior_dict)\n",
    "change_mean = False\n",
    "change_cov = True\n",
    "if change_mean:\n",
    "    new_prior_dict['prior_mean'] = orig_prior_dict['prior_mean'] + 10\n",
    "if change_cov:\n",
    "    new_prior_dict['prior_cov'] = 0.001 * orig_prior_dict['prior_cov']\n",
    "\n",
    "# Get the linear prediction at the new prior.\n",
    "pred_norm_param_dict = \\\n",
    "    prior_sens.predict_opt_par_from_hyper_par(new_prior_dict)\n",
    "\n",
    "# Re-optimize to check the prior sensitivity.\n",
    "model.prior_dict = new_prior_dict\n",
    "new_opt_par = get_optimum(norm_pattern.flatten(opt_norm_param_dict, free=True))\n",
    "new_norm_param_dict = norm_pattern.fold(new_opt_par.x, free=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicted mu differences:\n",
      "[-3.08005884e-05 -2.38177322e-04 -7.44514769e-04]\n",
      "Actual mu differences:\n",
      "[-0.02730183 -0.22125823 -0.62122988]\n",
      "Predicted sigma differences:\n",
      "[[1.89986626e-09 1.46910782e-08 4.59252342e-08]\n",
      " [1.46910782e-08 1.13601566e-07 3.55125641e-07]\n",
      " [4.59252342e-08 3.55125641e-07 1.11014540e-06]]\n",
      "Actual sigma differences:\n",
      "[[0.00074707 0.00605409 0.01700023]\n",
      " [0.00605409 0.04906074 0.13776533]\n",
      " [0.01700023 0.13776533 0.38685287]]\n"
     ]
    }
   ],
   "source": [
    "# Look at the differences.\n",
    "pred_diff = get_norm_param_diff(\n",
    "    pred_norm_param_dict, opt_norm_param_dict)\n",
    "true_diff = get_norm_param_diff(\n",
    "    new_norm_param_dict, opt_norm_param_dict)\n",
    "for param in ['mu', 'sigma']:\n",
    "    print('Predicted {} differences:\\n{}'.format(param, pred_diff[param]))\n",
    "    print('Actual {} differences:\\n{}'.format(param, true_diff[param]))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "OrderedDict:\n",
      "\t[prior_mean] = Array (3,) (lb=-inf, ub=inf)\n",
      "\t[prior_cov] = PDMatrix 3x3 (diag_lb = 0.0)\n",
      "OrderedDict:\n",
      "\t[mu] = Array (3,) (lb=-inf, ub=inf)\n",
      "\t[sigma] = PDMatrix 3x3 (diag_lb = 0.0)\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 288x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "cross_hess = prior_sens._hyper_obj_cross_hess(prior_sens._opt0, prior_sens._hyper0)\n",
    "plt.matshow(cross_hess == 0)\n",
    "print(prior_pattern)\n",
    "print(norm_pattern)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 7.73098959e-06  1.70951517e-05  7.62429175e-06  6.45010172e-09\n",
      "   7.51271374e-07  1.62971032e-06  1.47359237e-06  3.97125225e-06\n",
      "   1.44698156e-06]\n",
      " [ 1.70951517e-05  2.11019615e-04  1.95507177e-05  1.42627882e-08\n",
      "   1.80576773e-06  2.01168643e-05  3.26072686e-06  4.19123095e-05\n",
      "   3.71044667e-06]\n",
      " [ 7.62429175e-06  1.95507177e-05  3.82830937e-04  6.36108182e-09\n",
      "   7.43148407e-07  1.86380367e-06  1.76638420e-06  4.02063809e-05\n",
      "   7.26558381e-05]\n",
      " [-6.16795395e-09 -1.36388889e-08 -6.08282805e-09 -5.14603337e-12\n",
      "  -5.99380867e-10 -1.30021883e-09 -1.17566448e-09 -3.16835260e-09\n",
      "  -1.15443379e-09]\n",
      " [-9.37677144e-09 -4.79058450e-08 -9.66955615e-09 -7.82320670e-12\n",
      "  -9.33872507e-10 -4.56694692e-09 -1.78764463e-09 -1.00136599e-08\n",
      "  -1.83514350e-09]\n",
      " [ 5.85992030e-13 -3.40470418e-08 -5.28473198e-10  4.88903543e-16\n",
      "  -2.83501871e-11 -3.24576328e-09 -3.29701652e-13 -6.51202198e-09\n",
      "  -1.00296657e-10]\n",
      " [-2.93150572e-08 -6.52451202e-08 -8.77829502e-08 -2.44580721e-11\n",
      "  -2.84909018e-09 -6.21992996e-09 -5.63681757e-09 -2.07510911e-08\n",
      "  -1.66599488e-08]\n",
      " [ 2.81343850e-12 -1.33086245e-07 -7.07192571e-08  2.34730163e-15\n",
      "  -1.10768005e-10 -1.26873416e-08 -5.84683799e-11 -3.19996554e-08\n",
      "  -1.34215038e-08]\n",
      " [ 1.08476606e-12  2.77307834e-12 -1.42440604e-07  9.05039565e-16\n",
      "   1.05726250e-13  2.64362346e-13 -1.18634849e-10 -1.35785824e-08\n",
      "  -2.70331900e-08]]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<matplotlib.colorbar.Colorbar at 0x7f4fb906ca20>"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAUAAAAD8CAYAAAAG730QAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADl0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uIDMuMC4xLCBodHRwOi8vbWF0cGxvdGxpYi5vcmcvDW2N/gAAHFtJREFUeJzt3X+wX3V95/HnKwkERAFJ3BVIVuIk6oZW0WWi1t2OJbUJ1iHOSMcwqwUHJo4D9VdnLewf2mXqzLI/SqsF2wyBpZSasKm1t06EqthROxoIP0uAzN6CSrK4ShKDWg3ce1/7x/mEfrlz7/d7bvL93pvv/bweM2f8fj/nc97n843knc85n3M+H9kmIqJGC+a6ARERcyUJMCKqlQQYEdVKAoyIaiUBRkS1kgAjolpJgBFRrSTAiKhWEmBEVGvRIIKeqJN8kk4ZRGgAtGCwedsTEwON35wkb+DE0fsFP+M5H9axxFj3a6d4/4HxVnXve/jwXbbXH8v5jkcDSYAn6RTesvjCQYQGYMHJJw0sNsDEz38x0PgAPnx44OcYKB3T373jgwZ8AeTB/UO6c+Krxxxj/4Fx7rnr37Squ/DM/7P0mE94HBpIAoyI45+BCWbhauc4lgQYUSljnne7S+D5KgkwomLpAUZElYwZr3wwLgkwomITJAFGRIUMjCcBRkStau8BtnoQStJ6SXskjUq6etCNiojBM/C83Wqbr3r2ACUtBG4A3gHsBe6VNGL70UE3LiIGx7j6S+A2PcA1wKjtJ2w/B2wFNgy2WRExcIbxltt81SYBng081fF9byl7EUmbJO2StOt5D/5Vsog4Ns2bIO22+apvgyC2NwObAU5dsGQe/5sRMV+IcebBO93HoE0C3Acs7/i+rJRFxBBrBkHqToBtLoHvBVZJWiHpRGAjMDLYZkXEoDXPAarV1kuvJ0UkLZa0rezfKemcjn3XlPI9ktb1iilpi6SHJD0sabukl5byyyT9SNKDZbuiV7t7JkDbY8BVwF3AY8Adtnf3Oi4ijn8TVqutm44nRS4EVgOXSFo9qdrlwEHbK4HrgevKsatpOlXnAuuBGyUt7BHzY7bfYPv1wPdp8tMR22yfV7abev3+VvcAbe8AdrSpGxHD4UgPsA9eeFIEQNKRJ0U6H5XbAPx++bwd+BNJKuVbbR8GnpQ0WuIxXUzbz5YyASeXn3JUMiV+RKWMGGdBq62HNk+KvFCnXFUeApZ0ObZrTEm3AD8AXgd8tqPeezoujTvHLqaUBBhRsRlcAi898phb2TbNZbttfwA4i+a23HtL8d8C55RL468At/aKk3eBIyplxHNe2Lb6M7bPn2ZfmydFjtTZK2kRcBqwv8exXWPaHi+Xxp8AbrG9v2P3TcB/6/Wj0gOMqFTzIPSCVlsPbZ4UGQEuLZ8vBu627VK+sYwSrwBWAfdMF1ONlfDCPcCLgMfL9zM7zncRTe+wq/QAIyrWj0EQ22OSjjwpshC42fZuSdcCu2yPAFuA28ogxwGahEapdwfNgMkYcKXdzNM/TcwFwK2STgUEPAR8qDTlw5IuKnEOAJf1ars8gJkeTl2wxFkVrrusCnccGPJV4Z71gWP6P+E1v3yybxg5p1Xd33j14/d1uQQeWgPpAWrBgoEmqcf++2sGFhvg3179TwONDzA+6AQ44AS18IyXDzT++MFDA40PsHDlOQONPz763YHG74eJvAoXETVqBkHqTgF1//qIih0ZBKlZEmBExcYrnwwhCTCiUkfeBKlZEmBExSacBBgRFWomQ0gCjIgKGfF8+1fh5qUkwIhK2TBe+SVwz18v6WZJP5T0yGw0KCJmi5houc1XbdL//6KZqTUi5hHT9ADbbPNVz0tg29/onL8/IuaPDIJERJVM7/U+5ru+JcAyQ+wmgJMWnNKvsBExIM2ymHX3gQayMPppi16RhdEjjntZGL3u9B9RMZM3Qdo8BvN54NvAayXtlXT54JsVEbOhXwujD6s2o8CXzEZDImJ22aq+B5hL4IhKNYMgeRUuIqqkef2Qcxt1//qIijWDIK0XRu9K0npJeySNSrp6iv2LJW0r+3d2vlwh6ZpSvkfSul4xJW2R9JCkhyVtl/TSXueYThJgRMXGWdBq60bSQuAG4EJgNXCJpNWTql0OHLS9ErgeuK4cu5pmicxzaV65vVHSwh4xP2b7DbZfD3wfuKrbObpJAoyo1JE3QfrQA1wDjNp+wvZzwFZgw6Q6G4Bby+ftwNqysPkGYKvtw7afBEZLvGlj2n4WXlgY/WSazmy3c0wrCTCiYhMsaLUBSyXt6tg2dYQ5G3iq4/veUsZUdWyPAYeAJV2O7RpT0i3AD4DXAZ/tcY5pDWQQxBMTA11cfNDr9u74x7sHGh9g3VnnDfYEA1jwvtP4gYMDjT8rJga3cDnAxH94/eCC7/rmMYew4fmJ1n2gZ46nhdFtf6BcJn8WeC9wy9HESQ8wolLNJfCCVlsP+4DlHd+XlbIp60haBJwG7O9ybM+YtsdpLo3f0+Mc00oCjKhYn94EuRdYJWmFpBNpBjVGJtUZAS4tny8G7rbtUr6xjOCuAFYB90wXU42V8MI9wIuAx3ucY1p5DjCiUkcegznmOPaYpKuAu4CFwM22d0u6FthlewTYAtwmaRQ4QJPQKPXuAB4FxoArS8+OaWIuAG6VdCog4CHgQ6UpU56jmyTAiGr171U42zuAHZPKPtnx+RfAb01z7KeBT7eMOQG8bZo4055jOkmAERWbz+t9tJEEGFGpZhQ47wJHRIUyJX4SYETVar8EbjMh6nJJX5f0qKTdkj4yGw2LiMHq52QIw6pND3AM+F3b90t6GXCfpK/YfnTAbYuIAcuEqD3Yfhp4unz+iaTHaN65SwKMGGK2GEsCbK/Mr/VGYOcgGhMRs2s+X9620ToBlkkH/wr46JHpaCbt/5d1gXlJ3xoYEYPRrzdBhlmrBCjpBJrkd7vtL0xVp3Nd4FMXLMm6wBFDIAmwh/LC8RbgMdt/OPgmRcRsyHOA7WaDeRvwfuACSQ+W7Z0DbldEzIIJ1Gqbr9qMAn8L5vGfQESlbBhrPyHqvJQ3QSIqVvslcBJgRKVyDzAJMKJqTgKMiFrN5wGONpIAIypl5x5gEmBEtcR45aPAdf/6iMrZarX1Imm9pD2SRiVdPcX+xZK2lf07y7wCR/ZdU8r3SFrXK6ak20v5I5JuLm+qIentkg51PK/8SXoYTA/QxocPDyQ0wPgAY8MsLFo+Hwx44fXZMD765EDjLxgdYHD//NhD0J9L4LJA+Q3AO4C9wL2SRiZNmXc5cND2SkkbgeuA90paTbN627nAWcBXJb2mHDNdzNuB95U6fwlcAXyufP+m7Xe1bXt6gBG1cvPvWJuthzXAqO0nbD9Hs1j5hkl1NgC3ls/bgbXlNdsNwFbbh20/CYyWeNPGtL3DBc0awsuO9o8gCTCiYn16Fe5s4KmO73tL2ZR1bI8Bh4AlXY7tGbNc+r4fuLOj+K2SHpL0ZUnn9mp4BkEiKuWZDYIslbSr4/vmMgPUXLoR+Ibtb5bv9wOvsv3TMl/BF4FV3QIkAUZUbAa3cp+xff40+/YByzu+LytlU9XZK2kRcBqwv8ex08aU9CngFcAHj5R1zlNqe4ekGyUttf3MdD8ql8ARFevTKPC9wCpJKySdSDOoMTKpzghwafl8MXB3uYc3Amwso8QraHps93SLKekKYB1wie2JIyeQ9MpyXxFJa2jy2/5uDU8PMKJSzQDHsY8C2x6TdBVwF7AQuNn2bknXArtsj9DMKXqbpFHgAE1Co9S7g2aNoTHgStvjAFPFLKf8U+B7wLdLvvuC7WtpEuuHJI0BPwc2liQ7LfXYf1RO1Rl+s9b2PW5ENHb6azzrA8eUvU5eeZZf/T83tar76Lv/y31dLoGHVpsZoU8CvgEsLvW32/7UoBsWEYM3Dx7nPCZtLoEPAxeUkZUTgG9J+rLt7wy4bRExQEZMVP4qXJsZoQ38tHw9oWyV/7sRMT/U/he5VfqXtFDSg8APga/YzrrAEcPO/XsXeFi1SoC2x22fR/MszhpJvzS5jqRNknZJ2vU8g31XNyL6xC23eWpGNwBs/xj4OrB+in2bbZ9v+/wTWNyv9kXEAKUH2IOkV0g6vXw+mWZ2hscH3bCIGCwDExNqtc1XbUaBzwRuLVPeLADusP2lwTYrIgbOwDzu3bXRZhT4YeCNs9CWiJhleQ4wIuqVBBgRdZrfAxxtJAFG1Cw9wIioksHzeIS3jSTAiKolAUZErXIJHBHVSgKMiCrlQegkwIia5UHoiKhXRoEjolaqvAdY93zYETVrOxdgiyQpab2kPZJGJV09xf7FkraV/TslndOx75pSvkfSul4xJd1eyh+RdHNZqgM1PlPqPyzpTb3anQQYUS01gyBttm5RmpmibgAuBFYDl0haPana5cBB2yuB64HryrGraZbIPJdmntEbywz03WLeDrwO+GXgZOCKUn4hzbrCq4BNwOd6/QkkAUbUrD89wDXAqO0nbD8HbAU2TKqzAbi1fN4OrC2LmG8Atto+bPtJYLTEmzam7R0uaBZRX9Zxjj8vu74DnC7pzG4NTwKMqNlEyw2WHlnyomydCwqfDTzV8X1vKWOqOrbHgEPAki7H9oxZLn3fD9w5g3a8SOtBkNIl3QXss/2utsdFxHFqZs8BPnMcLox+I/AN29882gAzGQX+CPAYcOrRniwiji99GgXeByzv+L6slE1VZ6+kRcBpwP4ex04bU9KngFcAH5xhO16k7bKYy4DfBG5qUz8ihkR/7gHeC6yStELSiTSDGiOT6owAl5bPFwN3l3t4I8DGMkq8gmYA455uMSVdAawDLrE9Mekcv11Gg98CHLL9dLeGt+0B/hHwCeBlLetHRCVsj0m6CrgLWAjcbHu3pGuBXbZHgC3AbZJGgQM0CY1S7w7gUWAMuNL2OMBUMcsp/xT4HvDtZhyFL9i+FtgBvJNmIOWfgQ/0anvPBCjpXcAPbd8n6e1d6m2iGXrmJF7SK2xEHAf69SC07R00Caiz7JMdn38B/NY0x34a+HSbmKV8yrxVepRXzqTdbXqAbwMukvRO4CTgVEl/Yft9k06+GdgMcKrOqPz58oghYKp/Fa7nPUDb19heZvscmm7r3ZOTX0QMqT69CTKs8i5wRMVqfxd4RgnQ9t8Dfz+QlkTE7EsCjIhqJQFGRI3kXAInAUbUrPJR4CTAiIqlBxgR9UoCjIgq5R5gEmBE1ZIAI6JWmuhdZz7LjNARUa30ACNqlkvgiKhSBkGSACOqlgQYEdVKAoyIGomMAicBRtQq9wDzGExE1fo0I7Sk9ZL2SBqVdPUU+xdL2lb275R0Tse+a0r5HknresWUdFUps6SlHeVvl3RI0oNle2FNkum06gFK+i7wE2AcGDsOF0iOiKPRhx6gpIXADcA7gL3AvZJGbD/aUe1y4KDtlZI2AtcB75W0mmapjXOBs4CvSnpNOWa6mP8AfImpJ2f+pu13tW37TC6Bf832MzOoHxHHuT5dAq8BRm0/ASBpK7CBZqnLIzYAv18+bwf+RM2alhuArbYPA0+WZTPXlHpTxrT9QCk75obnEjiiZv25BD4beKrj+95SNmUd22PAIWBJl2PbxJzKWyU9JOnLks7tVbltD9DA30ky8GdlCcwXybrAEUPGMxoFXippV8f3zVPlgTl2P/Aq2z8ty/h+EVjV7YC2CfDf294n6V8BX5H0uO1vdFbIusARQ6j939Rnutz73wcs7/i+rJRNVWevpEXAacD+Hsf2ivkitp/t+LxD0o2Slna7ddfqEtj2vvK/PwT+mn+5Ro+IIXZkXZBeWw/3AqskrZB0Is2gxsikOiPApeXzxTTri7uUbyyjxCtoemz3tIz54t8ivbLcV0TSGpr8tr/bMT0ToKRTJL3syGfgN4BHeh0XEUOgD/cAyz29q4C7gMeAO2zvlnStpItKtS3AkjLI8XHg6nLsbuAOmgGTO4ErbY9PFxNA0ocl7aXpFT4s6aZyjouBRyQ9BHwG2FiS7LTUYz+SXk3T64PmkvkvbX+62zGn6gy/WWu7xo2Io7fTX+NZHzimYdCT//Vyr/yPH29V95HrP37ffHz8rec9wDIM/YZZaEtEzCKRN0HyKlxExZIAI6JeSYARUa0kwIioUmaDSQKMqFoSYETUKhOiRkS1cgkcEXVqOdnpfJYEGFGzJMCIqFHeBEkCjKiaJurOgEmAEbXKPcAkwIia5RI4IuqVBBgRtaq9B9hqSnxJp0vaLulxSY9JeuugGxYRs6BPC6MPq7Y9wD8G7rR9cZmfP8u+RQy7ma0KNy/1TICSTgN+FbgMwPZzwHODbVZEDFqeA2x3CbwC+BFwi6QHJN1UFkd6EUmbJO2StOt5Dve9oRExAHa7rQdJ6yXtkTQq6eop9i+WtK3s3ynpnI5915TyPZLW9Yop6apSZklLO8ol6TNl38OS3tSr3W0S4CLgTcDnbL8R+BllRadOtjfbPt/2+SewuEXYiJhr/VgWU9JC4AbgQmA1cImk1ZOqXQ4ctL0SuB64rhy7mmbJy3OB9cCNkhb2iPkPwK8D35t0jgtpltVcBWwCPtfr97dJgHuBvbZ3lu/baRJiRAyztgMgvTuAa4BR20+UW2RbgQ2T6mwAbi2ftwNryxq+G4Cttg/bfhIYLfGmjWn7AdvfnaIdG4A/d+M7wOmSzuzW8J4J0PYPgKckvbYUraVZwzMihpwm2m09nA081fF9bymbsk5Z8/cQsKTLsW1iHk07XqTtKPDvALeXEeAngA+0PC4ijmMzGAVeKmlXx/fNtjf3v0Wzq1UCtP0gMO8WRY6ommk1wFE802Vh9H3A8o7vy0rZVHX2SloEnAbs73Fsr5hH044XafUgdETMT/0YBAHuBVZJWlGuEjcCI5PqjACXls8XA3fbdinfWEaJV9AMYNzTMuZkI8Bvl9HgtwCHbD/d7YC8ChdRsz48B2h7TNJVwF3AQuBm27slXQvssj0CbAFukzQKHKBJaJR6d9CMK4wBV9oeh+Zxl8kxS/mHgU8ArwQelrTD9hXADuCdNAMp/0yLW3Vy+y5wa6fqDL9Za/seNyIaO/01nvUBHUuMl718uc97+0da1f3WF//TfV0ugYdWeoARtbIzIepcNyAi5lDd+S8JMKJmtb8LnAQYUSsDuQSOiGrVnf+SACNqlkvgiKhWRoEjok7zfLr7NpIAIyrVzAhddwZMAoyoWdYEiYhapQcYEXXKPcDe02FJeq2kBzu2ZyV9dDYaFxGD1LwL3Gabr3r2AG3vAc6DFxY/2Qf89YDbFRGzIZfAM7IW+Cfbk1djiohhk4XRZ5wANwKfH0RDImIOVN4DbD0lfpmW+iLgf0+zPwujRwyb/iyLObRm0gO8ELjf9v+bamdZIWozNDNC96FtETFgmqj7GngmCfAScvkbMX+YPAjdppKkU4B3AB8cbHMiYrYIV/8gdKt7gLZ/ZnuJ7UODblBEzCK73daDpPWS9kgalXT1FPsXS9pW9u+UdE7HvmtK+R5J63rFLEtl7izl28r4BJIuk/SjjmeWr+jV7qwLHFGzPiTA8nzwDTTjBKuBSyStnlTtcuCg7ZXA9cB15djVNE+XnAusB26UtLBHzOuA60usgyX2Edtsn1e2m3r9/CTAiFoduQfYZutuDTBq+wnbzwFbgQ2T6mwAbi2ftwNrJamUb7V92PaTNGv6rpkuZjnmghKDEvPdM//xjSTAiIppYqLVBiw98phb2TZ1hDkbeKrj+95SxlR1bI8Bh4AlXY6drnwJ8OMSY6pzvUfSw5K2S1re6/dnMoSIarW7v1c8MwQLo/8t8HnbhyV9kKZ3eEG3A9IDjKiV6dcgyD6gs7e1rJRNWUfSIuA0YH+XY6cr3w+cXmK86Fy299s+8hbGTcC/69XwJMCImvXnHuC9wKoyOnsizaDGyKQ6I8Cl5fPFwN22Xco3llHiFcAq4J7pYpZjvl5iUGL+DYCkMzvOdxHwWK+G5xI4omL9eA7Q9pikq4C7gIXAzbZ3S7oW2GV7BNgC3CZpFDhAk9Ao9e4AHgXGgCttjwNMFbOc8veArZL+AHigxAb4sKSLSpwDwGUtfn//H4Q8VWf4zVrb97gR0djpr/GsD+hYYpx28pn+lXMua1X3zsf/631DcA9wxtIDjKiVDeN1vwuXBBhRs8pfhUsCjKhZEmBEVMnAPF7vo40kwIhqGZx7gBFRI5NBkLluQETMocrvAbZ6E0TSxyTtlvSIpM9LOmnQDYuIWdCn+QCHVZuF0c8GPgycb/uXaJ7K3jjohkXEoLVMfvM4Aba9BF4EnCzpeeAlwP8dXJMiYlYYqHxRpJ49QNv7gP8BfB94Gjhk++8G3bCImAWV9wDbXAK/nGbW1hXAWcApkt43Rb2sCxwxVMqrcG22earNIMivA0/a/pHt54EvAL8yuZLtzbbPt33+CSzudzsjot8M9kSrbb5qcw/w+8BbJL0E+DmwFtg10FZFxOzImyDd2d4paTtwP808Ww8AmwfdsIiYBfP4/l4brUaBbX8K+NSA2xIRs8mufhQ4b4JE1Cw9wIiok/H4+Fw3Yk4lAUbUKtNhZVW4iKp5ot3Wg6T1kvZIGpV09RT7F0vaVvbvlHROx75rSvkeSet6xSwrxe0s5dvKqnFdzzGdJMCIShnwhFtt3UhaCNwAXAisBi6RtHpStcuBg7ZXAtcD15VjV9PMLXAusB64UdLCHjGvA64vsQ6W2NOeo5skwIha2f3qAa4BRm0/Yfs5YCvN22OdNgC3ls/bgbWSVMq32j5s+0lgtMSbMmY55oISgxLz3T3OMa0kwIiKeXy81dbD2cBTHd/3lrIp69geAw4BS7ocO135EuDHJcbkc013jmkNZBDkJxx85qve/r0ZHLIUeGYQbZklaf/cG/bfMNP2v+pYT/gTDt71VW9f2rL6SZI63wDbbHvoX4gYSAK0/YqZ1Je0a5gXXU77596w/4a5aL/t9X0KtQ9Y3vF9WSmbqs5eSYuA04D9PY6dqnw/cLqkRaWX11l/unNMK5fAEXGs7gVWldHZE2kGNUYm1RkBLi2fLwbutu1SvrGM4K4AVgH3TBezHPP1EoMS8296nGNaeQ4wIo6J7TFJVwF30cwYf7Pt3ZKuBXbZHgG2ALdJGgUOUGaVL/XuAB6lmWvgStvjAFPFLKf8PWCrpD+gmZtgSymf8hzdqEeCnBWSNg3z/YS0f+4N+28Y9vYPq+MiAUZEzIXcA4yIas1pAuz1+szxTtJySV+X9GhZNvQjc92mo1GevH9A0pfmui0zJel0SdslPS7pMUlvnes2zUSWnJ1bc5YAW74+c7wbA37X9mrgLcCVQ/gbAD4CPDbXjThKfwzcaft1wBsYot+RJWfn3lz2ANu8PnNcs/207fvL55/Q/OWb/AT8cU3SMuA3gZvmui0zJek04Fcpo4C2n7P947lt1YwdWXJ2EVlydtbNZQJs8/rM0CgzT7wR2Dm3LZmxPwI+AQzj1MArgB8Bt5RL+JsknTLXjWorS87OvQyC9IGklwJ/BXzU9rNz3Z62JL0L+KHt++a6LUdpEfAm4HO23wj8DBiae8ltl5yNwZnLBNjm9ZnjnqQTaJLf7ba/MNftmaG3ARdJ+i7NLYgLJP3F3DZpRvYCe20f6XVvp0mIw6LVkrMxOHOZANu8PnNcK1PtbAEes/2Hc92embJ9je1lts+h+fO/2/bQ9EBs/wB4StJrS9FamjcKhsULS86W/5bWMkSDOPPBnL0KN93rM3PVnqP0NuD9wD9KerCU/WfbO+awTbX5HeD28o/oE8AH5rg9rWXJ2bmXN0EioloZBImIaiUBRkS1kgAjolpJgBFRrSTAiKhWEmBEVCsJMCKqlQQYEdX6/1wia2BZlILYAAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<Figure size 432x288 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "# Note: it does not seem to be working for sigma.\n",
    "\n",
    "print(prior_sens.get_dopt_dhyper())\n",
    "\n",
    "plt.imshow(prior_sens.get_dopt_dhyper())\n",
    "plt.colorbar()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
