{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import paragami\n",
    "\n",
    "import autograd\n",
    "from autograd import numpy as np\n",
    "\n",
    "# Use the original scipy for functions we don't need to differentiate.\n",
    "import scipy as osp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.seed(42)\n",
    "\n",
    "num_obs = 10000\n",
    "data_dim = 3\n",
    "\n",
    "# True values of parameters\n",
    "true_sigma = \\\n",
    "    np.eye(3) * np.diag(np.arange(0, data_dim)) + \\\n",
    "    np.random.random((data_dim, data_dim)) * 0.1\n",
    "true_sigma = 0.5 * (true_sigma + true_sigma.T)\n",
    "true_mu = np.arange(0, data_dim)\n",
    "\n",
    "true_norm_param_dict = dict()\n",
    "true_norm_param_dict['mu'] = true_mu\n",
    "true_norm_param_dict['sigma'] = true_sigma\n",
    "\n",
    "# Data\n",
    "data = np.random.multivariate_normal(\n",
    "    mean=true_norm_param_dict['mu'],\n",
    "    cov=true_norm_param_dict['sigma'],\n",
    "    size=(num_obs, ))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss at true parameter: 103.94712761511776\n"
     ]
    }
   ],
   "source": [
    "def get_mvn_log_probs(obs, mean, cov):\n",
    "    cov_inv = np.linalg.inv(cov)\n",
    "    cov_det_sign, cov_log_det = np.linalg.slogdet(cov)\n",
    "    if cov_det_sign <= 0:\n",
    "        return np.full(float('inf'), obs.shape[0])\n",
    "    else:\n",
    "        obs_centered = obs - np.expand_dims(mean, axis=0)\n",
    "        return -0.5 * (\n",
    "            np.einsum('ni,ij,nj->n', obs_centered, cov_inv, obs_centered) + \\\n",
    "            cov_log_det)\n",
    "\n",
    "def get_data_lp(data, norm_param_dict, weights):\n",
    "    data_lp = np.sum(weights *\n",
    "                     get_mvn_log_probs(\n",
    "                         data,\n",
    "                         mean=norm_param_dict['mu'],\n",
    "                         cov=norm_param_dict['sigma']))\n",
    "    return data_lp\n",
    "\n",
    "def get_prior_lp(norm_param_dict, prior_param_dict):\n",
    "    prior_lp = get_mvn_log_probs(\n",
    "        obs=np.expand_dims(norm_param_dict['mu'], axis=0),\n",
    "        mean=prior_param_dict['prior_mean'],\n",
    "        cov=prior_param_dict['prior_cov'])\n",
    "\n",
    "    # Sum so as to return a scalar.\n",
    "    return np.sum(prior_lp)\n",
    "\n",
    "def get_loss(data, norm_param_dict, prior_param_dict, weights):\n",
    "    return -1 * (get_prior_lp(norm_param_dict, prior_param_dict) +\n",
    "                 get_data_lp(data, norm_param_dict, weights))\n",
    "    \n",
    "class NormalModel():\n",
    "    def __init__(self, data):\n",
    "        self.data = data\n",
    "        self.num_obs = self.data.shape[0]\n",
    "        self.data_dim = self.data.shape[1]\n",
    "                \n",
    "        # Reasonable defaults for the priors and weights.\n",
    "        self.set_prior(np.full(self.data_dim, 0.), 100 * np.eye(self.data_dim))\n",
    "        self.set_weights(np.full(self.num_obs, 1.0))\n",
    "                \n",
    "    def set_weights(self, weights):\n",
    "        self.weights = weights\n",
    "    \n",
    "    def set_prior(self, prior_mean, prior_cov):\n",
    "        self.prior_dict = dict()\n",
    "        self.prior_dict['prior_mean'] = prior_mean\n",
    "        self.prior_dict['prior_cov'] = prior_cov\n",
    "\n",
    "    def get_loss_for_opt(self, norm_param_dict):\n",
    "        return get_loss(\n",
    "            self.data, norm_param_dict, self.prior_dict, self.weights)\n",
    "    \n",
    "    def get_loss_by_prior(self, norm_param_dict, prior_dict):\n",
    "        return get_loss(\n",
    "            self.data, norm_param_dict, prior_dict, self.weights)\n",
    "\n",
    "    def get_loss_by_weights(self, norm_param_dict, weights):\n",
    "        return get_loss(\n",
    "            self.data, norm_param_dict, self.prior_dict, weights)\n",
    "\n",
    "    \n",
    "model = NormalModel(data)\n",
    "print('Loss at true parameter: {}'.format(model.get_loss_for_opt(true_norm_param_dict)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Define patterns."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "norm_pattern = paragami.PatternDict()\n",
    "norm_pattern['mu'] = paragami.NumericArrayPattern(shape=(data_dim, ))\n",
    "norm_pattern['sigma'] = paragami.PSDMatrixPattern(size=data_dim)\n",
    "\n",
    "prior_pattern = paragami.PatternDict()\n",
    "prior_pattern['prior_mean'] = paragami.NumericArrayPattern(shape=(data_dim, ))\n",
    "prior_pattern['prior_cov'] = paragami.PSDMatrixPattern(size=data_dim)\n",
    "\n",
    "weight_pattern = paragami.NumericArrayPattern(shape=(num_obs, ))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Warning: A bad approximation caused failure to predict improvement.\n",
      "         Current function value: 97.135404\n",
      "         Iterations: 19\n",
      "         Function evaluations: 21\n",
      "         Gradient evaluations: 18\n",
      "         Hessian evaluations: 18\n"
     ]
    }
   ],
   "source": [
    "# Optimize.\n",
    "opt_fun = paragami.FlattenedFunction(\n",
    "    original_fun=model.get_loss_for_opt,\n",
    "    patterns=norm_pattern,\n",
    "    free=True)\n",
    "opt_fun_grad = autograd.grad(opt_fun)\n",
    "opt_fun_hessian = autograd.hessian(opt_fun)\n",
    "\n",
    "# Initialize with zeros.\n",
    "init_param = np.zeros(norm_pattern.flat_length(free=True))\n",
    "mle_opt = osp.optimize.minimize(\n",
    "    method='trust-ncg',\n",
    "    x0=init_param,\n",
    "    fun=opt_fun,\n",
    "    jac=opt_fun_grad,\n",
    "    hess=opt_fun_hessian,\n",
    "    options={'gtol': 1e-8, 'disp': True})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "OrderedDict([('mu', array([0.00322004, 0.96876934, 1.88305126])), ('sigma', array([[0.03823283, 0.07566443, 0.03912985],\n",
      "       [0.07566443, 0.96271823, 0.09310977],\n",
      "       [0.03912985, 0.09310977, 1.95881609]]))])\n",
      "{'mu': array([0, 1, 2]), 'sigma': array([[0.03745401, 0.07746864, 0.03950388],\n",
      "       [0.07746864, 1.01560186, 0.05110853],\n",
      "       [0.03950388, 0.05110853, 2.0601115 ]])}\n"
     ]
    }
   ],
   "source": [
    "opt_norm_param_dict = norm_pattern.fold(mle_opt.x, free=True)\n",
    "print(opt_norm_param_dict)\n",
    "print(true_norm_param_dict)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
