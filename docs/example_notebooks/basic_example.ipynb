{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import paragami\n",
    "\n",
    "import autograd\n",
    "from autograd import numpy as np\n",
    "from autograd import scipy as sp"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will begin by considering a simple symmetric positive-definite matrix.  In general, we can write:\n",
    "\n",
    "$$\n",
    "A = \\left[\n",
    "\\begin{matrix}\n",
    "a_{11} & a_{12} & a_{13}  \\\\\n",
    "a_{21} & a_{22} & a_{23}  \\\\\n",
    "a_{31} & a_{32} & a_{33}  \\\\\n",
    "\\end{matrix}\n",
    "\\right]\n",
    "$$\n",
    "\n",
    "...although, of course, symmetry and positive-definiteness impose constraints on the entries $a_{ij}$ of $A$ which we will discuss below."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Suppose we are interested in optimizing some function of $A$, say, a sample covariance with a regularization penalty on the log determinant (denoted $\\log |A|$).\n",
    "\n",
    "Let the data be $X = \\left(x_1, ..., x_N\\right)$, where $x_n \\in \\mathbb{R}^3$, and write a loss function as\n",
    "\n",
    "$$\n",
    "\\ell\\left(X, A\\right) = \\sum_{n=1}^N \\left(\\frac{1}{2}x_n^T A x_n - \\lambda \\log |A| \\right).\n",
    "$$\n",
    "\n",
    "Let's simulate some data that is appropriate for this loss function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1000, 3)\n",
      "7063.652727102428\n"
     ]
    }
   ],
   "source": [
    "N = 1000\n",
    "\n",
    "# True value of A\n",
    "true_a = np.eye(3) * np.diag(np.array([1, 2, 3])) + np.random.random((3, 3)) * 0.1\n",
    "true_a = 0.5 * (true_a + true_a.T)\n",
    "\n",
    "# Data\n",
    "x = np.random.multivariate_normal(mean=np.zeros(3), cov=true_a, size=(N, ))\n",
    "print(x.shape)\n",
    "\n",
    "# Regularization constant\n",
    "lam = 1.0\n",
    "\n",
    "def loss(x, lam, a):\n",
    "    a_det_sign, a_log_det = np.linalg.slogdet(a)\n",
    "    assert a_det_sign > 0\n",
    "    return 0.5 * np.einsum('ni,ij,nj', x, a, x) - lam * a_log_det\n",
    "\n",
    "print(loss(x, lam, true_a))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We would like to minimize the function `loss` using tools like `scipy.optimize.minimize`, but standard optimization functions take vectors, not matrices, as input, and typically require the vector to take valid values in the entire domain."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let us first consider how to represent $A$ as a vector, and then as an unconstrained vector.\n",
    "\n",
    "Because $A$ is symmetric, $a_{21} = a_{12}$, $a_{31} = a_{13}$, and $a_{23} = a_{32}$.  This means that to reproduce $A$ we only need to store the bold values:\n",
    "\n",
    "$$\n",
    "A = \\left[\n",
    "\\begin{matrix}\n",
    "\\mathbf{a_{11}} & \\mathbf{a_{12}} & \\mathbf{a_{13}}  \\\\\n",
    "a_{21} & \\mathbf{a_{22}} & \\mathbf{a_{23}}  \\\\\n",
    "a_{31} & a_{32} & \\mathbf{a_{33}}  \\\\\n",
    "\\end{matrix}\n",
    "\\right]\n",
    "$$\n",
    "\n",
    "If we wanted to represent $A$ as an flat array, we could write\n",
    "\n",
    "$$\n",
    "A_{flat} = \\left[\n",
    "\\begin{matrix}\n",
    "\\mathbf{a_{11}} \\\\\n",
    "\\mathbf{a_{12}} \\\\\n",
    "\\mathbf{a_{22}} \\\\\n",
    "\\mathbf{a_{13}} \\\\\n",
    "\\mathbf{a_{23}} \\\\\n",
    "\\mathbf{a_{33}} \\\\\n",
    "\\end{matrix}\n",
    "\\right]\n",
    "$$\n",
    "\n",
    "and fully recover $A$ from $A_{flat}$."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Converting to and from $A$ and $A_{flat}$ can be done with the `flatten` method of a `paragami.PSDMatrixPattern` pattern.  \n",
    "\n",
    "For the moment, because we are simply re-stacking the values of $A$ into a vector, not transforming into an unconstrained space, we use the option `free=False`.  We will discuss the `free=True` option shortly."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Now, a_flat contains the elements of a exactly as shown in the formula above.\n",
      "\n",
      "a:\n",
      "[[1.15853698 0.88840844 0.49051765]\n",
      " [0.88840844 1.34573747 0.34190524]\n",
      " [0.49051765 0.34190524 1.83957984]]\n",
      "\n",
      "a_flat:\n",
      "[1.15853698 0.88840844 1.34573747 0.49051765 0.34190524 1.83957984]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# A sample positive definite matrix.\n",
    "a = np.eye(3) + np.random.random((3, 3))\n",
    "a = 0.5 * (a + a.T)\n",
    "\n",
    "# Define a pattern and fold.\n",
    "a_pattern = paragami.PSDMatrixPattern(size=3)\n",
    "a_flat = a_pattern.flatten(a, free=False)\n",
    "\n",
    "print('Now, a_flat contains the elements of a exactly as shown in the formula above.\\n')\n",
    "print('a:\\n{}\\n'.format(a))\n",
    "print('a_flat:\\n{}\\n'.format(a_flat))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can also convert from $A_{flat}$ back to $A$ by 'folding'."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Folding the flattened value recovers the original matrix.\n",
      "\n",
      "a:\n",
      "[[1.15853698 0.88840844 0.49051765]\n",
      " [0.88840844 1.34573747 0.34190524]\n",
      " [0.49051765 0.34190524 1.83957984]]\n",
      "\n",
      "a_fold:\n",
      "[1.15853698 0.88840844 1.34573747 0.49051765 0.34190524 1.83957984]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print('Folding the flattened value recovers the original matrix.\\n')\n",
    "a_fold = a_pattern.fold(a_flat, free=False)\n",
    "print('a:\\n{}\\n'.format(a))\n",
    "print('a_fold:\\n{}\\n'.format(a_flat))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Not every length-six vector represents a valide positive definite matrix.  If the attribute `validate` of a `paragami.PSDMatrixPattern` is true, then folding automatically checks for validity."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The diagonal of a positive definite matrix must be greater than 0, and folding checks this when validate=True, which it is by default:\n",
      "\n",
      "A bad folded value: [-1  0  0  0  0  0]\n",
      "Folding with a_pattern raised the following ValueError:\n",
      "Diagonal is less than the lower bound 0.0.\n",
      "\n",
      "If validate is false, folding will produce an invalid matrix without an error:\n",
      "\n",
      "Folding a non-pd matrix with validate=False:\n",
      "[[-1.  0.  0.]\n",
      " [ 0.  0.  0.]\n",
      " [ 0.  0.  0.]]\n",
      "\n",
      "However, it will not produce a matrix of the wrong shape even when validate is False:\n",
      "\n",
      "A very bad folded value: [1 0 0].\n",
      "Folding with a_pattern raised the following ValueError:\n",
      "Wrong length for PDMatrix flat value.\n"
     ]
    }
   ],
   "source": [
    "print('The diagonal of a positive definite matrix must be greater',\n",
    "      'than 0, and folding checks this when validate=True, which it is by default:\\n')\n",
    "a_flat_bad = np.array([-1, 0, 0, 0, 0, 0])\n",
    "print('A bad folded value: {}'.format(a_flat_bad))\n",
    "try:\n",
    "    a_fold_bad = a_pattern.fold(a_flat_bad, free=False)\n",
    "except ValueError as err:\n",
    "    print('Folding with a_pattern raised the following ValueError:\\n{}'.format(err))\n",
    "\n",
    "print('\\nIf validate is false, folding will produce an invalid matrix without an error:\\n')\n",
    "a_pattern.validate = False\n",
    "a_fold_bad = a_pattern.fold(a_flat_bad, free=False)\n",
    "print('Folding a non-pd matrix with validate=False:\\n{}'.format(a_fold_bad))\n",
    "\n",
    "print('\\nHowever, it will not produce a matrix of the wrong shape even when validate is False:\\n')\n",
    "a_flat_very_bad = np.array([1, 0, 0])\n",
    "print('A very bad folded value: {}.'.format(a_flat_very_bad))\n",
    "try:\n",
    "    a_fold_very_bad = a_pattern.fold(a_flat_very_bad, free=False)\n",
    "except ValueError as err:\n",
    "    print('Folding with a_pattern raised the following ValueError:\\n{}'.format(err))\n",
    "\n",
    "# Let's set validate back to true.\n",
    "a_pattern.validate = True"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "Sometimes (e.g. when performing optimization) it is convenient to have a flattened value that can legally take any value of the correct length.  For a positive definite matrix, this can be achieved by a Cholesky decomposition.  The details aren't important here, as `paragami` takes care of the transformation behind the scenes with the option `free=True`. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The free flat value a_freeflat is not immediately recognizable as a.\n",
      "\n",
      "a:\n",
      "[[1.15853698 0.88840844 0.49051765]\n",
      " [0.88840844 1.34573747 0.34190524]\n",
      " [0.49051765 0.34190524 1.83957984]]\n",
      "\n",
      "a_freeflat:\n",
      "[ 0.07357899  0.82538719 -0.20438018  0.45572168 -0.04200638  0.24433082]\n",
      "\n",
      "However, it transforms correctly back to a when folded.\n",
      "\n",
      "a_fold:\n",
      "[[1.15853698 0.88840844 0.49051765]\n",
      " [0.88840844 1.34573747 0.34190524]\n",
      " [0.49051765 0.34190524 1.83957984]]\n",
      "\n",
      "Any length-six vector will free fold back to a valid positive  semi-definite matrix up to floating point error.\n",
      "\n"
     ]
    },
    {
     "ename": "AssertionError",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAssertionError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-43-df48848bd029>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     17\u001b[0m     \u001b[0ma_rand_freeflat\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrandom\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnormal\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mscale\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m5\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msize\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m6\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     18\u001b[0m     \u001b[0ma_rand_fold\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0ma_pattern\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfold\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ma_rand_freeflat\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfree\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 19\u001b[0;31m     \u001b[0massert_is_pd\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ma_rand_fold\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     20\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     21\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-43-df48848bd029>\u001b[0m in \u001b[0;36massert_is_pd\u001b[0;34m(mat)\u001b[0m\n\u001b[1;32m     13\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0massert_is_pd\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmat\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     14\u001b[0m     \u001b[0meigvals\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlinalg\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0meigvals\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmat\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 15\u001b[0;31m     \u001b[0;32massert\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0meigvals\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m>=\u001b[0m \u001b[0;34m-\u001b[0m\u001b[0;36m1e-8\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     16\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mraw\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m100\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     17\u001b[0m     \u001b[0ma_rand_freeflat\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrandom\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnormal\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mscale\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m5\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msize\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m6\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mAssertionError\u001b[0m: "
     ]
    }
   ],
   "source": [
    "print('The free flat value a_freeflat is not immediately recognizable as a.\\n')\n",
    "a_freeflat = a_pattern.flatten(a, free=True)\n",
    "print('a:\\n{}\\n'.format(a))\n",
    "print('a_freeflat:\\n{}\\n'.format(a_freeflat))\n",
    "\n",
    "print('However, it transforms correctly back to a when folded.\\n')\n",
    "a_freefold = a_pattern.fold(a_freeflat, free=True)\n",
    "print('a_fold:\\n{}\\n'.format(a_freefold))\n",
    "\n",
    "print('Any length-six vector will free fold back to a valid positive ',\n",
    "      'semi-definite matrix up to floating point error.\\n')\n",
    "# Draw random free vectors and confirm that they are positive semi definite.\n",
    "def assert_is_pd(mat):\n",
    "    eigvals = np.linalg.eigvals(mat)\n",
    "    assert np.min(eigvals) >= -1e-8\n",
    "for raw in range(100):\n",
    "    a_rand_freeflat = np.random.normal(scale=2, size=(6, ))\n",
    "    a_rand_fold = a_pattern.fold(a_rand_freeflat, free=True)\n",
    "    assert_is_pd(a_rand_fold)\n",
    "\n",
    "\n",
    "print('Note that you will get an incorrect values or errors if you mix',\n",
    "      'free and non-free folding and flattening!\\n')\n",
    "try:\n",
    "    a_fold_bad = a_pattern.fold(a_freeflat, free=False)\n",
    "except ValueError as err:\n",
    "    print('Folding with a_pattern raised the following ValueError:\\n{}'.format(err))\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
