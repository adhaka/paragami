{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Flattening and Folding for Optimization and Frequentist Covariances."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import autograd\n",
    "from autograd import numpy as np\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "import paragami\n",
    "\n",
    "# Use the original scipy (\"osp\") for functions we don't need to differentiate.\n",
    "# When using scipy functions in functions that are passed to autograd,\n",
    "# use autograd.scipy instead.\n",
    "import scipy as osp"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Using Flattening and Folding for Optimization."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### An Example Model."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Suppose we are interested in optimizing some function of $A$, say, a normal model in which the data $x_n \\sim \\mathcal{N}(0, A)$.  Specifically, Let the data be $X = \\left(x_1, ..., x_N\\right)$, where $x_n \\in \\mathbb{R}^3$, and write a loss function as\n",
    "\n",
    "$$\n",
    "\\ell\\left(X, A\\right) =\n",
    "    -\\sum_{n=1}^N \\log P(x_n | A) =\n",
    "    \\frac{1}{2}\\sum_{n=1}^N \\left(x_n^T A^{-1} x_n - \\log|A|\\right) \n",
    "$$\n",
    "\n",
    "Let's simulate some data under this model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X shape: (100, 3)\n"
     ]
    }
   ],
   "source": [
    "np.random.seed(42)\n",
    "\n",
    "num_obs = 100\n",
    "\n",
    "# True value of A\n",
    "true_a = np.eye(3) * np.diag(np.array([1, 2, 3])) + np.random.random((3, 3)) * 0.1\n",
    "true_a = 0.5 * (true_a + true_a.T)\n",
    "\n",
    "# Data\n",
    "def draw_data(num_obs, true_a):\n",
    "    return np.random.multivariate_normal(\n",
    "        mean=np.zeros(3), cov=true_a, size=(num_obs, ))\n",
    "\n",
    "x = draw_data(num_obs, true_a)\n",
    "print('X shape: {}'.format(x.shape))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can estimate the covariance matrix using the negative log likelihood as a loss function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss at true parameter: 242.28536625488033\n"
     ]
    }
   ],
   "source": [
    "def get_loss(x, a):\n",
    "    num_obs = x.shape[0]\n",
    "    a_inv = np.linalg.inv(a)\n",
    "    a_det_sign, a_log_det = np.linalg.slogdet(a)\n",
    "    assert a_det_sign > 0\n",
    "    return 0.5 * (np.einsum('ni,ij,nj', x, a_inv, x) + num_obs * a_log_det)\n",
    "\n",
    "print('Loss at true parameter: {}'.format(get_loss(x, true_a)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Using ``autograd`` and ``scipy.optimize`` with ``paragami``."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We would like to minimize the function `loss` using tools like `scipy.optimize.minimize`.  Standard optimization functions take vectors, not matrices, as input, and often require the vector to take valid values in the entire domain.\n",
    "\n",
    "As-written, our loss function takes a positive definite matrix as an input.  We can wrap the loss as a funciton of the free flattened value using the `paragami.FlattenFunctionInput` class.  That is, we want to define a function $\\ell_{freeflat}$ so that\n",
    "\n",
    "$$\n",
    "\\ell_{freeflat}(X, A_{freeflat}) = \\ell(X, A).\n",
    "$$\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The two losses are the same when evalated on the folded and flat values:\n",
      "\n",
      "Original loss:\t\t242.28536625488033\n",
      "Free-flattened loss: \t242.28536625488036\n"
     ]
    }
   ],
   "source": [
    "a_pattern = paragami.PSDSymmetricMatrixPattern(size=3)\n",
    "\n",
    "# The arguments mean we're flatting the function get_loss, using\n",
    "# the pattern a_pattern, with free parameterization, and the paramater\n",
    "# is the second one (argnums uses 0-indexing like autograd).\n",
    "get_freeflat_loss = paragami.FlattenFunctionInput(\n",
    "    original_fun=get_loss, patterns=a_pattern, free=True, argnums=1)\n",
    "\n",
    "print('The two losses are the same when evalated on the folded and flat values:\\n')\n",
    "print('Original loss:\\t\\t{}'.format(get_loss(x, true_a)))\n",
    "true_a_freeflat = a_pattern.flatten(true_a, free=True)\n",
    "print('Free-flattened loss: \\t{}'.format(\n",
    "    get_freeflat_loss(x, true_a_freeflat)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The resulting function can be passed directly to `autograd` and `scipy.optimize`, and we can estimate\n",
    "\n",
    "$$\n",
    "\\hat{A}_{freeflat} := \\mathrm{argmin}_{A_{freeflat}} \\ell_{freeflat}(X, A_{freeflat}).\n",
    "$$\n",
    "\n",
    "Note that (as of writing) ``A bad approximation caused failure to predict improvement`` errors are common with second order methods even when optimization was successful.  This is because  ``osp.optimize.minimize`` only uses the norm of the gradient before multiplication by the inverse Hessian as a convergence criterion."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Optimization status: A bad approximation caused failure to predict improvement.\n",
      "Optimal value: 239.37556057055355\n"
     ]
    }
   ],
   "source": [
    "get_freeflat_loss_grad = autograd.grad(get_freeflat_loss, argnum=1)\n",
    "get_freeflat_loss_hessian = autograd.hessian(get_freeflat_loss, argnum=1)\n",
    "\n",
    "def get_optimum(x, init_val):\n",
    "    loss_opt = osp.optimize.minimize(\n",
    "        method='trust-ncg',\n",
    "        x0=init_val,\n",
    "        fun=lambda par: get_freeflat_loss(x, par),\n",
    "        jac=lambda par: get_freeflat_loss_grad(x, par),\n",
    "        hess=lambda par: get_freeflat_loss_hessian(x, par),\n",
    "        options={'gtol': 1e-8, 'disp': False})\n",
    "    return loss_opt\n",
    "\n",
    "init_val = np.zeros(a_pattern.flat_length(free=True))\n",
    "loss_opt = get_optimum(x, init_val)\n",
    "\n",
    "print('Optimization status: {}\\nOptimal value: {}'.format(\n",
    "      loss_opt.message, loss_opt.fun))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The optimization was in the free flattened space, so to get the optimal value of $A$ we must fold it.   We can see that the optimal value is close to the true value of $A$, though it differs due to randomness in $X$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True a:\n",
      "[[1.03745401 0.07746864 0.03950388]\n",
      " [0.07746864 2.01560186 0.05110853]\n",
      " [0.03950388 0.05110853 3.0601115 ]]\n",
      "\n",
      "Optimal a:\n",
      "[[ 1.13076002 -0.16382566  0.18449819]\n",
      " [-0.16382566  1.97854146  0.3020592 ]\n",
      " [ 0.18449819  0.3020592   2.78831733]]\n"
     ]
    }
   ],
   "source": [
    "optimal_freeflat_a = loss_opt.x\n",
    "optimal_a = a_pattern.fold(optimal_freeflat_a, free=True)\n",
    "print('True a:\\n{}\\n\\nOptimal a:\\n{}'.format(true_a, optimal_a))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Using Flattening and Folding with the Fisher Information for Frequentist Uncertainty."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Fisher Information and the Delta Method."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Suppose we wanted to use the Hessian of the objective (the observed Fisher information) to estimate a frequentist confidence region for $A$.  In standard notation, covariance is of a vector, so we can write what we want in terms of $A_{flat}$ as $\\mathrm{Cov}(A_{flat})$.\n",
    "The covariance between two elements of $A_{flat}$ corresponds to that between two elements of $A$.  For example, using the notation given above,\n",
    "\n",
    "$$\n",
    "\\mathrm{Cov}(a_{flat,1}, a_{flat,2}) = \\mathrm{Cov}(a_{11}, a_{12}) = \\mathrm{Cov}(a_{11}, a_{21})\\\\\n",
    "\\mathrm{Var}(a_{flat,4}) = \\mathrm{Var}(a_{21}) = \\mathrm{Var}(a_{12}),\n",
    "$$\n",
    "etc."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here, we will use the observed Fisher information of $\\ell_{freeflat}$ and the Delta method to estimate $\\mathrm{Cov}(A_{flat})$.\n",
    "\n",
    "$$\n",
    "\\begin{aligned}\n",
    "\\mathrm{Cov}(A_{freeflat}) &\\approx\n",
    "-\\left( \\left.\n",
    "\\frac{\\partial^2 \\ell_{freeflat}}{\\partial A_{freeflat} \\partial A_{freeflat}^T}\n",
    "\\right|_{\\hat{A}_{freeflat}} \\right)^{-1}\n",
    "&\\quad\\textrm{(Fisher information)}\n",
    "\\\\\n",
    "\\mathrm{Cov}(A_{free}) &\\approx\n",
    "\\left(\\frac{d A_{free}}{dA_{freeflat}^T}\\right)\n",
    "\\mathrm{Cov}(A_{freeflat})\n",
    "\\left(\\frac{d A_{free}}{dA_{freeflat}^T}\\right)^T\n",
    "&\\quad\\textrm{(Delta method)}\n",
    "\\end{aligned}\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The Hessian required for the covariance can be calculated directly using ``autograd``.  (Note that the loss is the negative of the log likelihood.)  The shape is, of course, the size of $A_{freeflat}$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The shape of the Fisher information amtrix is (6, 6).\n"
     ]
    }
   ],
   "source": [
    "fisher_info = -1 * get_freeflat_loss_hessian(x, loss_opt.x)\n",
    "print(\"The shape of the Fisher information amtrix is {}.\".format(fisher_info.shape))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The Jacobian matrix $\\frac{d A_{free}}{dA_{freeflat}^T}$ of the \"unfreeing transform\" $A_{free} = A_{free}(A_{freeflat})$ is provided by ``paragami`` as a function of the *folded* parameter.  Following standard notation for Jacobian matrices, the rows correspond to $A_{flat}$, the output of the unfreeing transform, and the columns correspond to $A_{freeflat}$, the input to the unfreeing transform.\n",
    "\n",
    "By default this Jacobian matrix is sparse (in large problems, most flat parameters are independent of most free flat parameters), but a dense matrix is fine in this small problem, so we use ``sparse=False``.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The shape of the Jacobian matrix is (9, 6).\n"
     ]
    }
   ],
   "source": [
    "freeing_jac = a_pattern.unfreeing_jacobian(optimal_a, sparse=False)\n",
    "print(\"The shape of the Jacobian matrix is {}.\".format(freeing_jac.shape))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can now plug in to estimate the covariance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Estimate the covariance of the flattened value using the Hessian at the optimum.\n",
    "a_flattened_cov = -1 * freeing_jac @ np.linalg.solve(fisher_info, freeing_jac.T)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### A Cautionary Note on Using the Fisher Information With Constrained Variables."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note that the estimated covariance is rank-deficient.  This is expected, since, for example, $A_{12}$ and $A_{21}$ cannot vary independently.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The shape of the covariance matrix is (9, 9).\n",
      "The rank of the covariance matrix is 6.\n"
     ]
    }
   ],
   "source": [
    "print('The shape of the covariance matrix is {}.'.format(a_flattened_cov.shape))\n",
    "print('The rank of the covariance matrix is {}.'.format(np.linalg.matrix_rank(a_flattened_cov)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Suppose we had erronously defined the function $\\ell_{flat}(A_{flat})$ and tried to estimate the covariance of $A$ using the Hessian of $\\ell_{flat}$.  Then the resulting Hessian would have been *full rank*, because the loss function ``get_loss`` does not enforce the constraint that $A$ be symmetric.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "An example of an erroneous use of Fisher information!\n",
      "The shape of the erroneous covariance matrix is (9, 9).\n",
      "The rank of the erroneous covariance matrix is 9.\n"
     ]
    }
   ],
   "source": [
    "print('An example of an erroneous use of Fisher information!')\n",
    "get_flat_loss = paragami.FlattenFunctionInput(\n",
    "    original_fun=get_loss, patterns=a_pattern, free=False, argnums=1)\n",
    "get_flat_loss_hessian = autograd.hessian(get_flat_loss, argnum=1)\n",
    "a_flat_opt = a_pattern.flatten(optimal_a, free=False)\n",
    "bad_fisher_info = get_flat_loss_hessian(x, a_flat_opt)\n",
    "\n",
    "bad_a_flattened_cov = -1 * np.linalg.inv(bad_fisher_info)\n",
    "\n",
    "print('The shape of the erroneous covariance matrix is {}.'.format(bad_a_flattened_cov.shape))\n",
    "print('The rank of the erroneous covariance matrix is {}.'.format(np.linalg.matrix_rank(bad_a_flattened_cov)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Theoretically, we are not justified using the Hessian of $\\ell_{flat}$ to estimate the covariance of its optimizer because the optimum is not \"interior\" -- that is, the argument $A_{flat}$ cannot take legal values in a neighborhood of the optimum, since such values may not be valid covariance matrices.  Overcoming this difficulty is a key advantage of using unconstrained parameterizations."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Inspecting and Checking the Result."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This shape of $\\mathrm{Cov}(A_{flat})$ is inconvenient because it's not obvious visually which entry of the flattened vector corresponds to which element of $A$.  Again, we can use folding to put the estimated marginal standard deviations in a readable shape.\n",
    "\n",
    "Because the result is not a valid covariance matrix, and we are just using the pattern for its shape, we set `validate` to `False`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The marginal standard deviations of the elements of A:\n",
      "[[0.15991362 0.15046908 0.17852051]\n",
      " [0.15046908 0.27980802 0.23681303]\n",
      " [0.17852051 0.23681303 0.39432762]]\n"
     ]
    }
   ],
   "source": [
    "a_pattern.verify = False\n",
    "a_sd = a_pattern.fold(np.sqrt(np.diag(a_flattened_cov)), free=False, validate_value=False)\n",
    "print('The marginal standard deviations of the elements of A:\\n{}'.format(a_sd))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As a sanity check, we can compare this estimated covariance with the variability incurred by drawing new datasets and re-optimizing."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "num_sims = 20\n",
    "optimal_a_draws = np.empty((num_sims, ) + true_a.shape)\n",
    "for sim in range(num_sims):\n",
    "    new_x = draw_data(num_obs, true_a)\n",
    "    new_loss_opt = get_optimum(new_x)\n",
    "    optimal_a_draws[sim] = a_pattern.fold(new_loss_opt.x, free=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Actual standard deviation:\n",
      "[[0.12203849 0.11104834 0.13347622]\n",
      " [0.11104834 0.25363392 0.24355346]\n",
      " [0.13347622 0.24355346 0.50647563]]\n",
      "Estimated standard deviation:\n",
      "[[0.15991362 0.15046908 0.17852051]\n",
      " [0.15046908 0.27980802 0.23681303]\n",
      " [0.17852051 0.23681303 0.39432762]]\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "a_sd_monte_carlo = np.std(optimal_a_draws, axis=0)\n",
    "\n",
    "plt.plot(a_sd_monte_carlo.flatten(), a_sd.flatten(), 'r.')\n",
    "plt.plot(a_sd_monte_carlo.flatten(), a_sd_monte_carlo.flatten(), 'k')\n",
    "plt.xlabel('Monte Carlo standard deviation')\n",
    "plt.ylabel('Fisher information +\\ndelta method standard deviation')\n",
    "plt.title('Comparision of estimated and exact standard deviations')\n",
    "\n",
    "print('Actual standard deviation:\\n{}'.format(a_sd_monte_carlo))\n",
    "print('Estimated standard deviation:\\n{}'.format(a_sd))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
