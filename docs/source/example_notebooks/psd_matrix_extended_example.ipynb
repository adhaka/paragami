{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Extended Example With Covariance Matrices. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import autograd\n",
    "from autograd import numpy as np\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "import paragami\n",
    "\n",
    "# Use the original scipy (\"osp\") for functions we don't need to differentiate.\n",
    "# When using scipy functions in functions that are passed to autograd,\n",
    "# use autograd.scipy instead.\n",
    "import scipy as osp"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this example, we will consider flattening and folding a simple symmetric positive semi-definite matrix:\n",
    "\n",
    "$$\n",
    "A = \\left[\n",
    "\\begin{matrix}\n",
    "a_{11} & a_{12} & a_{13}  \\\\\n",
    "a_{21} & a_{22} & a_{23}  \\\\\n",
    "a_{31} & a_{32} & a_{33}  \\\\\n",
    "\\end{matrix}\n",
    "\\right].\n",
    "$$\n",
    "\n",
    "Of course, symmetry and positive semi-definiteness impose constraints on the entries $a_{ij}$ of $A$."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Flattening and Folding."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### In the Original Space."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let us first consider how to represent $A$ as a vector, which we call simply *flattening*, and then as an unconstrained vector, which we call *free flattening*.\n",
    "\n",
    "When a parameter is flattened, it is simply re-shaped as a vector.  Every number that was in the original parameter will occur exactly once in the flattened shape.  (In the present case of a matrix, this is exactly the same as ``np.flatten``.)\n",
    "\n",
    "$$\n",
    "A = \\left[\n",
    "\\begin{matrix}\n",
    "a_{11} & a_{12} & a_{13}  \\\\\n",
    "a_{21} & a_{22} & a_{23}  \\\\\n",
    "a_{31} & a_{32} & a_{33}  \\\\\n",
    "\\end{matrix}\n",
    "\\right]\n",
    "\\xrightarrow{flatten}\n",
    "A_{flat} = \n",
    "\\left[\n",
    "\\begin{matrix}\n",
    "a_{flat,1} \\\\\n",
    "a_{flat,2} \\\\\n",
    "a_{flat,3} \\\\\n",
    "a_{flat,4} \\\\\n",
    "a_{flat,5} \\\\\n",
    "a_{flat,6} \\\\\n",
    "a_{flat,7} \\\\\n",
    "a_{flat,8} \\\\\n",
    "a_{flat,9} \\\\\n",
    "\\end{matrix}\\right]\n",
    "=\n",
    "\\left[\n",
    "\\begin{matrix}\n",
    "a_{11} \\\\\n",
    "a_{12} \\\\\n",
    "a_{13} \\\\\n",
    "a_{21} \\\\\n",
    "a_{22} \\\\\n",
    "a_{23} \\\\\n",
    "a_{31} \\\\\n",
    "a_{32} \\\\\n",
    "a_{33} \\\\\n",
    "\\end{matrix}\n",
    "\\right]\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Converting to and from $A$ and $A_{flat}$ can be done with the `flatten` method of a `paragami.PSDSymmetricMatrixPattern` pattern.  \n",
    "\n",
    "For the moment, because we are flattening, not free flattening, we use the option `free=False`.  We will discuss the `free=True` option shortly."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Now, a_flat contains the elements of a exactly as shown in the formula above.\n",
      "\n",
      "a:\n",
      "[[1.86520859 0.78134038 0.72375918]\n",
      " [0.78134038 1.08398334 0.457461  ]\n",
      " [0.72375918 0.457461   1.04752021]]\n",
      "\n",
      "a_flat:\n",
      "[1.86520859 0.78134038 0.72375918 0.78134038 1.08398334 0.457461\n",
      " 0.72375918 0.457461   1.04752021]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# A sample positive semi-definite matrix.\n",
    "a = np.eye(3) + np.random.random((3, 3))\n",
    "a = 0.5 * (a + a.T)\n",
    "\n",
    "# Define a pattern and fold.\n",
    "a_pattern = paragami.PSDSymmetricMatrixPattern(size=3)\n",
    "a_flat = a_pattern.flatten(a, free=False)\n",
    "\n",
    "print('Now, a_flat contains the elements of a exactly as shown in the formula above.\\n')\n",
    "print('a:\\n{}\\n'.format(a))\n",
    "print('a_flat:\\n{}\\n'.format(a_flat))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can also convert from $A_{flat}$ back to $A$ by 'folding'."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Folding the flattened value recovers the original matrix.\n",
      "\n",
      "a:\n",
      "[[1.86520859 0.78134038 0.72375918]\n",
      " [0.78134038 1.08398334 0.457461  ]\n",
      " [0.72375918 0.457461   1.04752021]]\n",
      "\n",
      "a_fold:\n",
      "[[1.86520859 0.78134038 0.72375918]\n",
      " [0.78134038 1.08398334 0.457461  ]\n",
      " [0.72375918 0.457461   1.04752021]]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print('Folding the flattened value recovers the original matrix.\\n')\n",
    "a_fold = a_pattern.fold(a_flat, free=False)\n",
    "print('a:\\n{}\\n'.format(a))\n",
    "print('a_fold:\\n{}\\n'.format(a_fold))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "By default, flattening and folding perform checks to make sure the result is a valid instance of the parameter type -- in this case, a symmetric positive definite matrix. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The diagonal of a positive semi-definite matrix must not be less than 0, and folding checks this when validate=True, which it is by default:\n",
      "\n",
      "A bad folded value: [-1  0  0  0  0  0  0  0  0]\n",
      "Folding with a_pattern raised the following ValueError:\n",
      "Diagonal is less than the lower bound 0.0.\n",
      "\n",
      "If validate is false, folding will produce an invalid matrix without an error:\n",
      "\n",
      "Folding a non-pd matrix with validate=False:\n",
      "[[-1  0  0]\n",
      " [ 0  0  0]\n",
      " [ 0  0  0]]\n",
      "\n",
      "However, it will not produce a matrix of the wrong shape even when validate is False:\n",
      "\n",
      "A very bad folded value: [1 0 0].\n",
      "Folding with a_pattern raised the following ValueError:\n",
      "Wrong length for PSDSymmetricMatrix flat value.\n"
     ]
    }
   ],
   "source": [
    "print('The diagonal of a positive semi-definite matrix must not be less',\n",
    "      'than 0, and folding checks this when validate=True, which it is by default:\\n')\n",
    "a_flat_bad = np.array([-1, 0, 0,  0, 0, 0,  0, 0, 0])\n",
    "print('A bad folded value: {}'.format(a_flat_bad))\n",
    "try:\n",
    "    a_fold_bad = a_pattern.fold(a_flat_bad, free=False)\n",
    "except ValueError as err:\n",
    "    print('Folding with a_pattern raised the following ValueError:\\n{}'.format(err))\n",
    "\n",
    "print('\\nIf validate is false, folding will produce an invalid matrix without an error:\\n')\n",
    "a_fold_bad = a_pattern.fold(a_flat_bad, free=False, validate=False)\n",
    "print('Folding a non-pd matrix with validate=False:\\n{}'.format(a_fold_bad))\n",
    "\n",
    "print('\\nHowever, it will not produce a matrix of the wrong shape even when validate is False:\\n')\n",
    "a_flat_very_bad = np.array([1, 0, 0])\n",
    "print('A very bad folded value: {}.'.format(a_flat_very_bad))\n",
    "try:\n",
    "    a_fold_very_bad = a_pattern.fold(a_flat_very_bad, free=False, validate=False)\n",
    "except ValueError as err:\n",
    "    print('Folding with a_pattern raised the following ValueError:\\n{}'.format(err))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### In an Unconstrained Space: \"Free\" Flattening and Folding."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ordinary flattening converts a 3x3 symmetric PSD matrix into a 9-d vector.  However, as seen above, not every 9-d vector is a valid 3x3 symmetric positive definite matrix.  It is useful to have an \"free\" flattened representation of a parameter, where every finite value of the free flattened vector corresponds is guaranteed valid.\n",
    "\n",
    "To accomplish this for a symmetric positive definite matrix, we consider the Cholesky decomposition $A_{chol}$. This is an lower-triangular matrix with positive diagonal entries such that $A = A_{chol} A_{chol}^T$.  By taking the log of the diagonal of $A_{chol}$ and stacking the non-zero entries, we can construct a 6-d vector, every value of which corresponds to a symmetric PSD matrix.\n",
    "\n",
    "$$\n",
    "% A \\xrightarrow{\\textrm{free flatten}} A_{freeflat} \\quad\\quad \\textrm{where} \\\\\n",
    "A \\xrightarrow{}\n",
    "A_{chol} = \n",
    "\\left[\n",
    "\\begin{matrix}\n",
    "\\alpha_{11} & 0 & 0  \\\\\n",
    "\\alpha_{21} & \\alpha_{22} & 0  \\\\\n",
    "\\alpha_{31} & \\alpha_{32} & \\alpha_{33}  \\\\\n",
    "\\end{matrix}\n",
    "\\right] \\xrightarrow{}\n",
    "A_{freeflat} =\n",
    "\\left[\n",
    "\\begin{matrix}\n",
    "\\log(\\alpha_{11}) \\\\\n",
    "\\alpha_{21} \\\\\n",
    "\\alpha_{31} \\\\\n",
    "\\log(\\alpha_{22})\\\\\n",
    "\\alpha_{32} \\\\\n",
    "\\log(\\alpha_{33})\n",
    "\\end{matrix}\n",
    "\\right].\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The details of the freeing transform aren't important to the end user, as `paragami` takes care of the transformation behind the scenes with the option `free=True`.  We denote the flattened $A$ in the free parameterization as $A_{freeflat}$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The free flat value a_freeflat is not immediately recognizable as a.\n",
      "\n",
      "a:\n",
      "[[1.86520859 0.78134038 0.72375918]\n",
      " [0.78134038 1.08398334 0.457461  ]\n",
      " [0.72375918 0.457461   1.04752021]]\n",
      "\n",
      "a_freeflat:\n",
      "[ 0.31168645  0.57210609 -0.13940876  0.52994449  0.17735537 -0.15378995]\n",
      "\n",
      "However, it transforms correctly back to a when folded.\n",
      "\n",
      "a_fold:\n",
      "[[1.86520859 0.78134038 0.72375918]\n",
      " [0.78134038 1.08398334 0.457461  ]\n",
      " [0.72375918 0.457461   1.04752021]]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print('The free flat value a_freeflat is not immediately recognizable as a.\\n')\n",
    "a_freeflat = a_pattern.flatten(a, free=True)\n",
    "print('a:\\n{}\\n'.format(a))\n",
    "print('a_freeflat:\\n{}\\n'.format(a_freeflat))\n",
    "\n",
    "print('However, it transforms correctly back to a when folded.\\n')\n",
    "a_freefold = a_pattern.fold(a_freeflat, free=True)\n",
    "print('a_fold:\\n{}\\n'.format(a_freefold))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Any length-six vector will free fold back to a valid PSD matrix up to floating point error.  Let's draw 100 random vectors, fold them, and check that this is true.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Draw random free vectors and confirm that they are positive semi definite.\n",
    "def assert_is_pd(mat):\n",
    "    eigvals = np.linalg.eigvals(mat)\n",
    "    assert np.min(eigvals) >= -1e-8\n",
    "for draw in range(100):\n",
    "    a_rand_freeflat = np.random.normal(scale=2, size=(6, ))\n",
    "    a_rand_fold = a_pattern.fold(a_rand_freeflat, free=True)\n",
    "    assert_is_pd(a_rand_fold)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Using Flattening and Folding for Optimization."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### An Example Model."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Suppose we are interested in optimizing some function of $A$, say, a normal model in which the data $x_n \\sim \\mathcal{N}(0, A)$.  Specifically, Let the data be $X = \\left(x_1, ..., x_N\\right)$, where $x_n \\in \\mathbb{R}^3$, and write a loss function as\n",
    "\n",
    "$$\n",
    "\\ell\\left(X, A\\right) =\n",
    "    -\\sum_{n=1}^N \\log P(x_n | A) =\n",
    "    \\frac{1}{2}\\sum_{n=1}^N \\left(x_n^T A^{-1} x_n - \\log|A|\\right) \n",
    "$$\n",
    "\n",
    "Let's simulate some data under this model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X shape: (100, 3)\n",
      "Loss at true parameter: 242.28536625488033\n"
     ]
    }
   ],
   "source": [
    "np.random.seed(42)\n",
    "\n",
    "num_obs = 100\n",
    "\n",
    "# True value of A\n",
    "true_a = np.eye(3) * np.diag(np.array([1, 2, 3])) + np.random.random((3, 3)) * 0.1\n",
    "true_a = 0.5 * (true_a + true_a.T)\n",
    "\n",
    "# Data\n",
    "def draw_data(num_obs, true_a):\n",
    "    return np.random.multivariate_normal(\n",
    "        mean=np.zeros(3), cov=true_a, size=(num_obs, ))\n",
    "\n",
    "x = draw_data(num_obs, true_a)\n",
    "print('X shape: {}'.format(x.shape))\n",
    "\n",
    "def get_loss(x, a):\n",
    "    num_obs = x.shape[0]\n",
    "    a_inv = np.linalg.inv(a)\n",
    "    a_det_sign, a_log_det = np.linalg.slogdet(a)\n",
    "    assert a_det_sign > 0\n",
    "    return 0.5 * (np.einsum('ni,ij,nj', x, a_inv, x) + num_obs * a_log_det)\n",
    "\n",
    "print('Loss at true parameter: {}'.format(get_loss(x, true_a)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Using ``autograd`` and ``scipy.optimize`` with ``paragami``."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We would like to minimize the function `loss` using tools like `scipy.optimize.minimize`.  Standard optimization functions take vectors, not matrices, as input, and often require the vector to take valid values in the entire domain.\n",
    "\n",
    "As-written, our loss function takes a positive definite matrix as an input.  We can wrap the loss as a funciton of the free flattened value using the `paragami.FlattenedFunction` class.  That is, we want to define a function $\\ell_{freeflat}$ so that\n",
    "\n",
    "$$\n",
    "\\ell_{freeflat}(X, A_{freeflat}) = \\ell(X, A).\n",
    "$$\n",
    "\n",
    "\n",
    "The resulting function can be passed directly to `autograd` and `scipy.optimize`, and we can estimate\n",
    "\n",
    "$$\n",
    "\\hat{A}_{freeflat} := \\mathrm{argmin}_{A_{freeflat}} \\ell_{freeflat}(X, A_{freeflat})\n",
    "$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The two losses are the same when evalated on the folded and flat values:\n",
      "\n",
      "Original loss:\t\t242.28536625488033\n",
      "Free-flattened loss: \t242.28536625488036\n",
      "\n",
      "Now, use the flattened function to optimize with autograd.\n",
      "\n",
      "Optimization successful: False\n",
      "Optimal value: 239.37556057055355\n"
     ]
    }
   ],
   "source": [
    "# The arguments mean we're flatting the function get_loss, using\n",
    "# the pattern a_pattern, with free parameterization, and the paramater\n",
    "# is the second one (argnums uses 0-indexing like autograd).\n",
    "get_freeflat_loss = paragami.FlattenedFunction(\n",
    "    original_fun=get_loss, patterns=a_pattern, free=True, argnums=1)\n",
    "\n",
    "print('The two losses are the same when evalated on the folded and flat values:\\n')\n",
    "print('Original loss:\\t\\t{}'.format(get_loss(x, true_a)))\n",
    "true_a_freeflat = a_pattern.flatten(true_a, free=True)\n",
    "print('Free-flattened loss: \\t{}'.format(\n",
    "    get_freeflat_loss(x, true_a_freeflat)))\n",
    "\n",
    "print('\\nNow, use the flattened function to optimize with autograd.\\n')\n",
    "\n",
    "get_freeflat_loss_grad = autograd.grad(get_freeflat_loss, argnum=1)\n",
    "get_freeflat_loss_hessian = autograd.hessian(get_freeflat_loss, argnum=1)\n",
    "\n",
    "def get_optimum(x):\n",
    "    loss_opt = osp.optimize.minimize(\n",
    "        method='trust-ncg',\n",
    "        x0=np.zeros(a_pattern.flat_length(free=True)),\n",
    "        fun=lambda par: get_freeflat_loss(x, par),\n",
    "        jac=lambda par: get_freeflat_loss_grad(x, par),\n",
    "        hess=lambda par: get_freeflat_loss_hessian(x, par),\n",
    "        options={'gtol': 1e-8, 'disp': False})\n",
    "    return loss_opt\n",
    "\n",
    "loss_opt = get_optimum(x)\n",
    "print('Optimization successful: {}\\nOptimal value: {}'.format(\n",
    "    loss_opt.success, loss_opt.fun))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The optimization was in the free flattened space, so to get the optimal value of $A$ we must fold it.   We can see that the optimal value is close to the true value of $A$, though it differs due to randomness in $X$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True a:\n",
      "[[1.03745401 0.07746864 0.03950388]\n",
      " [0.07746864 2.01560186 0.05110853]\n",
      " [0.03950388 0.05110853 3.0601115 ]]\n",
      "\n",
      "Optimal a:\n",
      "[[ 1.13076002 -0.16382566  0.18449819]\n",
      " [-0.16382566  1.97854146  0.3020592 ]\n",
      " [ 0.18449819  0.3020592   2.78831733]]\n"
     ]
    }
   ],
   "source": [
    "optimal_freeflat_a = loss_opt.x\n",
    "optimal_a = a_pattern.fold(optimal_freeflat_a, free=True)\n",
    "print('True a:\\n{}\\n\\nOptimal a:\\n{}'.format(true_a, optimal_a))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Using Flattening and Folding with the Fisher Information for Frequentist Uncertainty."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Fisher Information and the Delta Method."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Suppose we wanted to use the Hessian of the objective (the observed Fisher information) to estimate a frequentist confidence region for $A$.  In standard notation, covariance is of a vector, so we can write what we want in terms of $A_{flat}$ as $\\mathrm{Cov}(A_{flat})$.\n",
    "The covariance between two elements of $A_{flat}$ corresponds to that between two elements of $A$.  For example, using the notation given above,\n",
    "\n",
    "$$\n",
    "\\mathrm{Cov}(a_{flat,1}, a_{flat,2}) = \\mathrm{Cov}(a_{11}, a_{12}) = \\mathrm{Cov}(a_{11}, a_{21})\\\\\n",
    "\\mathrm{Var}(a_{flat,4}) = \\mathrm{Var}(a_{21}) = \\mathrm{Var}(a_{12}),\n",
    "$$\n",
    "etc."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here, we will use the observed Fisher information of $\\ell_{freeflat}$ and the Delta method to estimate $\\mathrm{Cov}(A_{flat})$.\n",
    "\n",
    "$$\n",
    "\\begin{aligned}\n",
    "\\mathrm{Cov}(A_{freeflat}) &\\approx\n",
    "-\\left( \\left.\n",
    "\\frac{\\partial^2 \\ell_{freeflat}}{\\partial A_{freeflat} \\partial A_{freeflat}^T}\n",
    "\\right|_{\\hat{A}_{freeflat}} \\right)^{-1}\n",
    "&\\quad\\textrm{(Fisher information)}\n",
    "\\\\\n",
    "\\mathrm{Cov}(A_{free}) &\\approx\n",
    "\\left(\\frac{d A_{free}}{dA_{freeflat}^T}\\right)\n",
    "\\mathrm{Cov}(A_{freeflat})\n",
    "\\left(\\frac{d A_{free}}{dA_{freeflat}^T}\\right)^T\n",
    "&\\quad\\textrm{(Delta method)}\n",
    "\\end{aligned}\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The Hessian required for the covariance can be calculated directly using ``autograd``.  (Note that the loss is the negative of the log likelihood.)  The shape is, of course, the size of $A_{freeflat}$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The shape of the Fisher information amtrix is (6, 6).\n"
     ]
    }
   ],
   "source": [
    "fisher_info = -1 * get_freeflat_loss_hessian(x, loss_opt.x)\n",
    "print(\"The shape of the Fisher information amtrix is {}.\".format(fisher_info.shape))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The Jacobian matrix $\\frac{d A_{free}}{dA_{freeflat}^T}$ of the \"unfreeing transform\" $A_{free} = A_{free}(A_{freeflat})$ is provided by ``paragami`` as a function of the *folded* parameter.  Following standard notation for Jacobian matrices, the rows correspond to $A_{flat}$, the output of the unfreeing transform, and the columns correspond to $A_{freeflat}$, the input to the unfreeing transform.\n",
    "\n",
    "By default this Jacobian matrix is sparse (in large problems, most flat parameters are independent of most free flat parameters), but a dense matrix is fine in this small problem, so we use ``sparse=False``.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The shape of the Jacobian matrix is (9, 6).\n"
     ]
    }
   ],
   "source": [
    "freeing_jac = a_pattern.unfreeing_jacobian(optimal_a, sparse=False)\n",
    "print(\"The shape of the Jacobian matrix is {}.\".format(freeing_jac.shape))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can now plug in to estimate the covariance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Estimate the covariance of the flattened value using the Hessian at the optimum.\n",
    "a_flattened_cov = -1 * freeing_jac @ np.linalg.solve(fisher_info, freeing_jac.T)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### A Cautionary Note on Using the Fisher Information With Constrained Variables."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note that the estimated covariance is rank-deficient.  This is expected, since, for example, $A_{12}$ and $A_{21}$ cannot vary independently.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The shape of the covariance matrix is (9, 9).\n",
      "The rank of the covariance matrix is 6.\n"
     ]
    }
   ],
   "source": [
    "print('The shape of the covariance matrix is {}.'.format(a_flattened_cov.shape))\n",
    "print('The rank of the covariance matrix is {}.'.format(np.linalg.matrix_rank(a_flattened_cov)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Suppose we had erronously defined the function $\\ell_{flat}(A_{flat})$ and tried to estimate the covariance of $A$ using the Hessian of $\\ell_{flat}$.  Then the resulting Hessian would have been *full rank*, because the loss function ``get_loss`` does not enforce the constraint that $A$ be symmetric.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "An example of an erroneous use of Fisher information!\n",
      "The shape of the erroneous covariance matrix is (9, 9).\n",
      "The rank of the erroneous covariance matrix is 9.\n"
     ]
    }
   ],
   "source": [
    "print('An example of an erroneous use of Fisher information!')\n",
    "get_flat_loss = paragami.FlattenedFunction(\n",
    "    original_fun=get_loss, patterns=a_pattern, free=False, argnums=1)\n",
    "get_flat_loss_hessian = autograd.hessian(get_flat_loss, argnum=1)\n",
    "a_flat_opt = a_pattern.flatten(optimal_a, free=False)\n",
    "bad_fisher_info = get_flat_loss_hessian(x, a_flat_opt)\n",
    "\n",
    "bad_a_flattened_cov = -1 * np.linalg.inv(bad_fisher_info)\n",
    "\n",
    "print('The shape of the erroneous covariance matrix is {}.'.format(bad_a_flattened_cov.shape))\n",
    "print('The rank of the erroneous covariance matrix is {}.'.format(np.linalg.matrix_rank(bad_a_flattened_cov)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Theoretically, we are not justified using the Hessian of $\\ell_{flat}$ to estimate the covariance of its optimizer because the optimum is not \"interior\" -- that is, the argument $A_{flat}$ cannot take legal values in a neighborhood of the optimum, since such values may not be valid covariance matrices.  Overcoming this difficulty is a key advantage of using unconstrained parameterizations."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Inspecting and Checking the Result."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This shape of $\\mathrm{Cov}(A_{flat})$ is inconvenient because it's not obvious visually which entry of the flattened vector corresponds to which element of $A$.  Again, we can use folding to put the estimated marginal standard deviations in a readable shape.\n",
    "\n",
    "Because the result is not a valid covariance matrix, and we are just using the pattern for its shape, we set `validate` to `False`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The marginal standard deviations of the elements of A:\n",
      "[[0.15991362 0.15046908 0.17852051]\n",
      " [0.15046908 0.27980802 0.23681303]\n",
      " [0.17852051 0.23681303 0.39432762]]\n"
     ]
    }
   ],
   "source": [
    "a_pattern.verify = False\n",
    "a_sd = a_pattern.fold(np.sqrt(np.diag(a_flattened_cov)), free=False, validate=False)\n",
    "print('The marginal standard deviations of the elements of A:\\n{}'.format(a_sd))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As a sanity check, we can compare this estimated covariance with the variability incurred by drawing new datasets and re-optimizing."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "num_sims = 20\n",
    "optimal_a_draws = np.empty((num_sims, ) + true_a.shape)\n",
    "for sim in range(num_sims):\n",
    "    new_x = draw_data(num_obs, true_a)\n",
    "    new_loss_opt = get_optimum(new_x)\n",
    "    optimal_a_draws[sim] = a_pattern.fold(new_loss_opt.x, free=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Actual standard deviation:\n",
      "[[0.11447968 0.12298773 0.1601474 ]\n",
      " [0.12298773 0.29224341 0.22676115]\n",
      " [0.1601474  0.22676115 0.50484798]]\n",
      "Estimated standard deviation:\n",
      "[[0.15991362 0.15046908 0.17852051]\n",
      " [0.15046908 0.27980802 0.23681303]\n",
      " [0.17852051 0.23681303 0.39432762]]\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "a_sd_monte_carlo = np.std(optimal_a_draws, axis=0)\n",
    "\n",
    "plt.plot(a_sd_monte_carlo.flatten(), a_sd.flatten(), 'r.')\n",
    "plt.plot(a_sd_monte_carlo.flatten(), a_sd_monte_carlo.flatten(), 'k')\n",
    "plt.xlabel('Monte Carlo standard deviation')\n",
    "plt.ylabel('Fisher information +\\ndelta method standard deviation')\n",
    "plt.title('Comparision of estimated and exact standard deviations')\n",
    "\n",
    "print('Actual standard deviation:\\n{}'.format(a_sd_monte_carlo))\n",
    "print('Estimated standard deviation:\\n{}'.format(a_sd))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
