{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import autograd\n",
    "import autograd.numpy as np\n",
    "import autograd.scipy as sp\n",
    "import paragami\n",
    "import scipy as osp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "np.random.seed(42)\n",
    "\n",
    "num_obs = 1000\n",
    "\n",
    "# True values of parameters\n",
    "true_sigma = \\\n",
    "    np.eye(3) * np.diag(np.array([1, 2, 3])) + \\\n",
    "    np.random.random((3, 3)) * 0.1\n",
    "true_sigma = 0.5 * (true_sigma + true_sigma.T)\n",
    "\n",
    "true_mu = np.array([0, 1, 2])\n",
    "\n",
    "# Data\n",
    "x = np.random.multivariate_normal(\n",
    "    mean=true_mu, cov=true_sigma, size=(num_obs, ))\n",
    "\n",
    "# Original weights.\n",
    "original_weights = np.ones(num_obs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5149.567522214259"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def regularizer(par_dict, lam):\n",
    "    return lam * np.sum(par_dict['mu'] ** 2)\n",
    "\n",
    "def get_normal_log_prob(x, sigma, mu):\n",
    "    sigma_inv = np.linalg.inv(sigma)\n",
    "    sigma_det_sign, sigma_log_det = np.linalg.slogdet(sigma)\n",
    "    if sigma_det_sign <= 0:\n",
    "        return np.full(float('inf'), x.shape[0])\n",
    "    else:\n",
    "        x_centered = x - np.expand_dims(mu, axis=0)\n",
    "        return -0.5 * (\n",
    "            np.einsum('ni,ij,nj->n', x_centered, sigma_inv, x_centered) + \\\n",
    "            sigma_log_det)\n",
    "\n",
    "def model_logpdf(par_dict, weights, x):\n",
    "    # Note that the multivariate_normal.logpdf does not work when\n",
    "    # the arguments are passed as keyword arguments.\n",
    "    data_lpdf = \\\n",
    "        sp.stats.multivariate_normal.logpdf(\n",
    "            x, par_dict['mu'], par_dict['sigma'])\n",
    "    #data_lpdf = get_normal_log_prob(x, mu=par_dict['mu'], sigma=par_dict['sigma'])\n",
    "    return np.sum(weights * data_lpdf)\n",
    "\n",
    "def objective_fun(par_dict, weights, lam, x):\n",
    "    return -model_logpdf(par_dict, weights, x) + regularizer(par_dict, lam)\n",
    "\n",
    "norm_par = dict()\n",
    "norm_par['mu'] = true_mu\n",
    "norm_par['sigma'] = true_sigma\n",
    "\n",
    "original_lam = 0\n",
    "\n",
    "objective_fun(norm_par, original_weights, original_lam, x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 0.34540381  0.09413988  0.07870993]\n",
      " [ 0.09413988  0.15713758 -0.07289394]\n",
      " [ 0.07870993 -0.07289394  0.11167245]]\n",
      "[ 0.52563825 -0.42833438 -0.32206316]\n",
      "-4.15286246651169\n",
      "-4.15286246651169\n"
     ]
    }
   ],
   "source": [
    "model_logpdf_params_mu_grad = autograd.grad(autograd.scipy.stats.multivariate_normal.logpdf, argnum=2)\n",
    "print(model_logpdf_params_mu_grad(x[0, :], true_mu, true_sigma))\n",
    "\n",
    "model_logpdf_params_mu_grad = autograd.grad(autograd.scipy.stats.multivariate_normal.logpdf, argnum=1)\n",
    "print(model_logpdf_params_mu_grad(x[0, :], true_mu, true_sigma))\n",
    "\n",
    "print(autograd.scipy.stats.multivariate_normal.logpdf(x[0, :], true_mu, true_sigma))\n",
    "print(autograd.scipy.stats.multivariate_normal.logpdf(x[0, :], mean=true_mu, cov=true_sigma))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "norm_param_pattern = paragami.PatternDict()\n",
    "norm_param_pattern['sigma'] = paragami.PSDSymmetricMatrixPattern(size=3)\n",
    "norm_param_pattern['mu'] = paragami.NumericArrayPattern(shape=(3, ))\n",
    "\n",
    "def objective_par_only(par_dict):\n",
    "    return objective_fun(par_dict, original_weights, original_lam, x)\n",
    "\n",
    "objective_flat = paragami.FlattenFunctionInput(\n",
    "    #lambda par_dict: objective(par_dict, original_weights, original_lam, x),\n",
    "    objective_par_only,\n",
    "    patterns=norm_param_pattern,\n",
    "    free=True)\n",
    "\n",
    "norm_par_flat = norm_param_pattern.flatten(norm_par, free=True)\n",
    "assert(\n",
    "    objective_flat(norm_par_flat) == \\\n",
    "    objective_fun(norm_par, original_weights, original_lam, x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-5149.567522214259\n",
      "Fails:\n",
      "test_util.py 31:\tassert vspace(vjp_y) == x_vs\n",
      "-5149.567522214259\n",
      "Fails: Can't differentiate w.r.t. type <class 'numpy.int64'>\n"
     ]
    }
   ],
   "source": [
    "from autograd.test_util import check_grads\n",
    "\n",
    "num_obs = 1000\n",
    "\n",
    "# True values of parameters\n",
    "true_sigma = \\\n",
    "    np.eye(3) * np.diag(np.array([1, 2, 3])) + \\\n",
    "    np.random.random((3, 3)) * 0.1\n",
    "true_sigma = 0.5 * (true_sigma + true_sigma.T)\n",
    "\n",
    "true_mu = np.array([0, 1, 2])\n",
    "\n",
    "# Data\n",
    "x = np.random.multivariate_normal(\n",
    "    mean=true_mu, cov=true_sigma, size=(num_obs, ))\n",
    "\n",
    "# Succeeds\n",
    "check_grads(autograd.scipy.stats.multivariate_normal.logpdf, modes=['rev'])(x, true_mu, true_sigma)\n",
    "\n",
    "# Fails\n",
    "try:\n",
    "    def logpdf_mu(mu):\n",
    "        return np.sum(autograd.scipy.stats.multivariate_normal.logpdf(x, mu, true_sigma))\n",
    "    print(logpdf_mu(true_mu))\n",
    "    check_grads(logpdf_mu, modes=['rev'])(true_mu)\n",
    "except AssertionError as err:\n",
    "    print('Fails:\\ntest_util.py 31:\\tassert vspace(vjp_y) == x_vs')\n",
    "\n",
    "try:\n",
    "    def logpdf_mu(mu):\n",
    "        return np.sum(autograd.scipy.stats.multivariate_normal.logpdf(x, mean=mu, cov=true_sigma))\n",
    "    print(logpdf_mu(true_mu))\n",
    "    check_grads(logpdf_mu, modes=['rev'])(true_mu)\n",
    "except TypeError as err:\n",
    "    print('Fails: ' + str(err))\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "\n",
    "from autograd.test_util import check_grads\n",
    "\n",
    "objective_wrapper = paragami.OptimizationObjective(objective_flat)\n",
    "init_param = np.ones(norm_param_pattern.flat_length(free=True))\n",
    "\n",
    "check_grads(objective_flat, modes=['rev'])(init_param)\n",
    "objective_wrapper.set_print_every(0)\n",
    "check_grads(objective_wrapper.f, modes=['rev'])(init_param)\n",
    "\n",
    "\n",
    "objective_wrapper.set_print_every(1)\n",
    "objective_wrapper.reset()\n",
    "mle_opt = osp.optimize.minimize(\n",
    "    method='trust-ncg',\n",
    "    x0=init_param,\n",
    "    fun=objective_wrapper.f,\n",
    "    jac=objective_wrapper.grad,\n",
    "    hess=objective_wrapper.hessian,\n",
    "    options={'gtol': 1e-12, 'disp': False})\n",
    "print(mle_opt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(mle_opt.x)\n",
    "norm_par_opt = norm_param_pattern.fold(mle_opt.x, free=True)\n",
    "print(norm_par_opt)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
